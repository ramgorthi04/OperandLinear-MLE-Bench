{
  "cells": [
    {
      "id": "344871b2-a48e-43ed-9158-0a999117fc4a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final submission: per-model isotonic calibration ensemble for top-5 keys, strict thresholding, write submission.csv\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "print('Running per-model isotonic calibration ensemble...', flush=True)\n",
        "\n",
        "# Explicit top-5 keys from best subset\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "# Allow fallbacks for test preds (pick first existing)\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets_b4.npy', 'oof_targets.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float)\n",
        "        break\n",
        "if y is None:\n",
        "    raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths with fallbacks\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    opts = paths_te_opts.get(k, [])\n",
        "    chosen = None\n",
        "    for p in opts:\n",
        "        if os.path.exists(p):\n",
        "            chosen = p; break\n",
        "    if chosen is not None:\n",
        "        paths_te[k] = chosen\n",
        "\n",
        "# Load arrays\n",
        "oof_list = []; te_list = []; usable_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)):\n",
        "        print(f'Skip key {k}: missing OOF path', flush=True)\n",
        "        continue\n",
        "    if pt is None or (not os.path.exists(pt)):\n",
        "        print(f'Skip key {k}: missing TEST path', flush=True)\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    # Ensure finite\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        print(f'Skip key {k}: non-finite OOF', flush=True)\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    oof_list.append(a_oof); te_list.append(a_te); usable_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0:\n",
        "    raise RuntimeError('No usable models for per-model isotonic')\n",
        "\n",
        "print('Using keys:', usable_keys, flush=True)\n",
        "\n",
        "# Per-model isotonic calibration to map EV->target on OOF, then transform both OOF and Test\n",
        "cal_oof_list = []; cal_te_list = []\n",
        "for i, (a_oof, a_te) in enumerate(zip(oof_list, te_list)):\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy()\n",
        "    cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof)\n",
        "    cal_t = ir.transform(a_te)\n",
        "    cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    cal_oof_list.append(cal_o); cal_te_list.append(cal_t)\n",
        "\n",
        "# Equal-weight mean of calibrated EVs\n",
        "cal_oof_stack = np.stack(cal_oof_list, axis=1)\n",
        "cal_te_stack = np.stack(cal_te_list, axis=1)\n",
        "blend_oof = cal_oof_stack.mean(axis=1)\n",
        "blend_te = cal_te_stack.mean(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "def optimize_thresholds_strict(y_true, p, init=[0.57,1.42,2.43,3.19]):\n",
        "    y_true = np.asarray(y_true).astype(float); p = np.asarray(p).astype(float)\n",
        "    def _loss(th):\n",
        "        th = np.sort(th); th = np.clip(th, 0.3, 3.7)\n",
        "        for i in range(1,4):\n",
        "            if th[i] - th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "        cls = preds_to_classes(p, th)\n",
        "        return -cohen_kappa_score(y_true, cls, weights='quadratic')\n",
        "    res = minimize(_loss, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':1500, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    th = np.sort(res.x)\n",
        "    for i in range(1,4):\n",
        "        if th[i] - th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "    th = np.clip(th, 0.3, 3.7)\n",
        "    return th\n",
        "\n",
        "# Optimize thresholds on calibrated OOF\n",
        "mask_eval = np.isfinite(y) & np.isfinite(blend_oof)\n",
        "th0 = optimize_thresholds_strict(y[mask_eval], blend_oof[mask_eval], init=[0.57,1.42,2.43,3.19])\n",
        "q0 = cohen_kappa_score(y[mask_eval], preds_to_classes(blend_oof[mask_eval], th0), weights='quadratic')\n",
        "print('Per-model-iso OOF QWK:', f'{q0:.5f}', 'th:', th0, flush=True)\n",
        "\n",
        "# Optional small th3 safety nudge +0.02 if drop <= 0.0005\n",
        "t_safe = th0.copy(); t_safe[3] = min(3.7, t_safe[3] + 0.02)\n",
        "q_safe = cohen_kappa_score(y[mask_eval], preds_to_classes(blend_oof[mask_eval], t_safe), weights='quadratic')\n",
        "chosen_th = t_safe if (q0 - q_safe) <= 0.0005 else th0\n",
        "print('Chosen OOF QWK:', f\"{(q_safe if (q0 - q_safe) <= 0.0005 else q0):.5f}\", 'chosen_th:', chosen_th, flush=True)\n",
        "\n",
        "# Apply to Test and write submission\n",
        "cls = preds_to_classes(blend_te, chosen_th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_permodel_iso.npy', chosen_th)\n",
        "print('submission.csv written (per-model isotonic ensemble).', flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running per-model isotonic calibration ensemble...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-model-iso OOF QWK: 0.88606 th: [0.5878599  1.47499928 2.42169358 3.01298325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen OOF QWK: 0.88611 chosen_th: [0.5878599  1.47499928 2.42169358 3.03298325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (per-model isotonic ensemble).\n"
          ]
        }
      ]
    },
    {
      "id": "49ff720d-4516-42a0-8781-7e221eb5b39c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# NNLS-weighted blend on per-model isotonic calibrated EVs; write improved submission if any\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import minimize, nnls\n",
        "\n",
        "print('Running NNLS-weighted per-model isotonic ensemble...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets_b4.npy', 'oof_targets.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float)\n",
        "        break\n",
        "if y is None:\n",
        "    raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Load arrays and fit per-model isotonic\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0:\n",
        "    raise RuntimeError('No usable calibrated arrays')\n",
        "\n",
        "X = np.stack(oof_list, axis=1)  # (n, m)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "\n",
        "# NNLS to get non-negative weights\n",
        "w_raw, _ = nnls(A, b)\n",
        "if w_raw.sum() <= 0:\n",
        "    w = np.ones_like(w_raw) / len(w_raw)\n",
        "else:\n",
        "    w = w_raw / w_raw.sum()\n",
        "print('Used keys:', used_keys, 'weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "# Blends\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "def optimize_thresholds_strict(y_true, p, init=[0.57,1.42,2.43,3.03]):\n",
        "    y_true = np.asarray(y_true).astype(float); p = np.asarray(p).astype(float)\n",
        "    def _loss(th):\n",
        "        th = np.sort(th); th = np.clip(th, 0.3, 3.7)\n",
        "        for i in range(1,4):\n",
        "            if th[i] - th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "        cls = preds_to_classes(p, th)\n",
        "        return -cohen_kappa_score(y_true, cls, weights='quadratic')\n",
        "    res = minimize(_loss, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':1200, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    th = np.sort(res.x)\n",
        "    for i in range(1,4):\n",
        "        if th[i] - th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "    th = np.clip(th, 0.3, 3.7)\n",
        "    return th\n",
        "\n",
        "th = optimize_thresholds_strict(y[mask], blend_oof[mask], init=[0.5879, 1.4750, 2.4217, 3.0130])\n",
        "q = cohen_kappa_score(y[mask], preds_to_classes(blend_oof[mask], th), weights='quadratic')\n",
        "print('NNLS per-model-iso OOF QWK:', f'{q:.5f}', 'th:', th, flush=True)\n",
        "\n",
        "# Write submission\n",
        "cls = preds_to_classes(blend_te, th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_permodel_iso_nnls.npy', th); np.save('weights_permodel_iso_nnls.npy', w)\n",
        "print('submission.csv written (per-model-isotonic + NNLS weights).', flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running NNLS-weighted per-model isotonic ensemble...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640'] weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS per-model-iso OOF QWK: 0.88934 th: [0.59176262 1.6049918  2.37433822 2.91447651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (per-model-isotonic + NNLS weights).\n"
          ]
        }
      ]
    },
    {
      "id": "f692af4c-1d6a-40dd-9fe8-288420d8746b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extended set: per-model isotonic + NNLS over 8 models; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import minimize, nnls\n",
        "\n",
        "print('Running extended per-model isotonic + NNLS over up to 8 models...', flush=True)\n",
        "\n",
        "keys = [\n",
        "    'b5_512_rrcema',\n",
        "    'serx50_512_rrcema',\n",
        "    'b5_512',\n",
        "    'b4_512',\n",
        "    'b4_640',\n",
        "    'r200d_512_rrcema',\n",
        "    'convnextb_512_rrcema',\n",
        "    'serx50_512_rrcema_s2',\n",
        "]\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "    'serx50_512_rrcema_s2': 'oof_preds_serx50_512_rrc_ema_seed2026.npy',\n",
        "    'r200d_512_rrcema': 'oof_preds_r200d_512_rrc_ema.npy',\n",
        "    'convnextb_512_rrcema': 'oof_preds_convnextb_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema_s2': ['test_reg_preds_serx50_512_rrc_ema_seed2026.npy'],\n",
        "    'r200d_512_rrcema': ['test_reg_preds_r200d_512_rrc_ema.npy'],\n",
        "    'convnextb_512_rrcema': ['test_reg_preds_convnextb_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable calibrated arrays')\n",
        "\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('Used keys:', used_keys, 'weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "def optimize_thresholds_strict(y_true, p, init=[0.58,1.48,2.42,3.03]):\n",
        "    y_true = np.asarray(y_true).astype(float); p = np.asarray(p).astype(float)\n",
        "    def _loss(th):\n",
        "        th = np.sort(th); th = np.clip(th, 0.3, 3.7)\n",
        "        for i in range(1,4):\n",
        "            if th[i]-th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "        return -cohen_kappa_score(y_true, preds_to_classes(p, th), weights='quadratic')\n",
        "    res = minimize(_loss, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':1200, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    th = np.sort(res.x)\n",
        "    for i in range(1,4):\n",
        "        if th[i]-th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "    th = np.clip(th, 0.3, 3.7)\n",
        "    return th\n",
        "\n",
        "th = optimize_thresholds_strict(y[mask], blend_oof[mask])\n",
        "q = cohen_kappa_score(y[mask], preds_to_classes(blend_oof[mask], th), weights='quadratic')\n",
        "print('Extended NNLS per-model-iso OOF QWK:', f'{q:.5f}', 'th:', th, flush=True)\n",
        "\n",
        "# Write submission\n",
        "cls = preds_to_classes(blend_te, th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_permodel_iso_nnls_ext.npy', th); np.save('weights_permodel_iso_nnls_ext.npy', w)\n",
        "print('submission.csv written (extended per-model-isotonic + NNLS).', flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running extended per-model isotonic + NNLS over up to 8 models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640', 'r200d_512_rrcema', 'convnextb_512_rrcema', 'serx50_512_rrcema_s2'] weights: [0.3055 0.221  0.2014 0.1154 0.0595 0.     0.0971 0.    ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extended NNLS per-model-iso OOF QWK: 0.88895 th: [0.58037571 1.59126103 2.37320446 2.93342801]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (extended per-model-isotonic + NNLS).\n"
          ]
        }
      ]
    },
    {
      "id": "c44221db-e043-4b2c-ac73-f231d9fadbd9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Top-5 per-model isotonic + NNLS with 2D (th2, th3) grid refinement; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running top-5 per-model isotonic + NNLS with 2D threshold refinement...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model isotonic\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable calibrated arrays')\n",
        "\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('Used keys:', used_keys, 'weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Start from previous best NNLS per-model iso thresholds if exist, else use reasonable init\n",
        "t0 = np.array([0.5918, 1.6050, 2.3743, 2.9145], dtype=float)\n",
        "try:\n",
        "    t_prev = np.load('thresholds_permodel_iso_nnls.npy')\n",
        "    if t_prev.shape == (4,): t0 = t_prev.astype(float)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 2D grid around th2, th3\n",
        "th2_c, th3_c = float(t0[2]), float(t0[3])\n",
        "th2_min = max(0.6, th2_c - 0.12); th2_max = min(3.4, th2_c + 0.12)\n",
        "th3_min = max(th2_c + 0.12, th3_c - 0.12); th3_max = min(3.7, th3_c + 0.12)\n",
        "g2 = np.arange(th2_min, th2_max + 1e-12, 0.005)\n",
        "g3 = np.arange(th3_min, th3_max + 1e-12, 0.005)\n",
        "best_q = -1.0; best_th = t0.copy()\n",
        "y_m = y[mask]; p_m = blend_oof[mask]\n",
        "for i, t2 in enumerate(g2):\n",
        "    # enforce 0.12 gaps\n",
        "    t1_min = max(0.3, t2 - 2.0); t1_max = min(t2 - 0.12, 2.8)\n",
        "    t0_min = max(0.3, t1_min - 1.0); t0_max = min(t1_max - 0.12, 1.6)\n",
        "    # keep t0,t1 clamped to previous for speed but valid\n",
        "    th_try = best_th.copy()\n",
        "    th_try[2] = t2\n",
        "    # sweep th3 for this th2\n",
        "    for j, t3 in enumerate(g3):\n",
        "        if t3 - t2 < 0.12: continue\n",
        "        th_try[3] = t3\n",
        "        # ensure lower thresholds maintain gaps with new th2\n",
        "        if th_try[1] >= th_try[2]: th_try[1] = max(th_try[1], th_try[2] - 0.12)\n",
        "        if th_try[0] >= th_try[1]: th_try[0] = max(0.3, th_try[1] - 0.12)\n",
        "        q = cohen_kappa_score(y_m, preds_to_classes(p_m, th_try), weights='quadratic')\n",
        "        if q > best_q:\n",
        "            best_q = q; best_th = th_try.copy()\n",
        "    if (i+1) % 10 == 0:\n",
        "        print(f'grid row {i+1}/{len(g2)} best_q={best_q:.5f}', flush=True)\n",
        "\n",
        "print('2D grid best OOF QWK:', f'{best_q:.5f}', 'best_th:', best_th, flush=True)\n",
        "\n",
        "# Apply to test and save\n",
        "cls = preds_to_classes(blend_te, best_th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_permodel_iso_nnls_grid2d.npy', best_th); np.save('weights_permodel_iso_nnls_top5.npy', w)\n",
        "print('submission.csv written (top-5 per-model-iso + NNLS + 2D grid refine).', flush=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running top-5 per-model isotonic + NNLS with 2D threshold refinement...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640'] weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 10/49 best_q=0.88690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 20/49 best_q=0.88882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 30/49 best_q=0.88941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 40/49 best_q=0.88941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D grid best OOF QWK: 0.88941 best_th: [0.59176262 1.6049918  2.37433822 2.92947651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (top-5 per-model-iso + NNLS + 2D grid refine).\n"
          ]
        }
      ]
    },
    {
      "id": "96881efc-e123-465c-bc84-55bae954127b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add ordinal EV model into per-model isotonic + NNLS top-5, then 2D refine; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running top-5 + ordinal per-model isotonic + NNLS with 2D threshold refinement...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640', 'b5_ordinal']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "    'b5_ordinal': 'oof_ev_b5_ordinal.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "    'b5_ordinal': ['test_ev_b5_ordinal.npy'],\n",
        "}\n",
        "\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model isotonic\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable calibrated arrays')\n",
        "\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('Used keys:', used_keys, 'weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Start from last best if available\n",
        "t0 = np.array([0.5918, 1.6050, 2.3743, 2.9295], dtype=float)\n",
        "for cand in ['thresholds_permodel_iso_nnls_grid2d.npy', 'thresholds_permodel_iso_nnls.npy', 'thresholds_permodel_iso.npy']:\n",
        "    if os.path.exists(cand):\n",
        "        tt = np.load(cand)\n",
        "        if getattr(tt, 'shape', None) == (4,):\n",
        "            t0 = tt.astype(float); break\n",
        "\n",
        "# 2D grid around th2, th3\n",
        "th2_c, th3_c = float(t0[2]), float(t0[3])\n",
        "th2_min = max(0.6, th2_c - 0.12); th2_max = min(3.4, th2_c + 0.12)\n",
        "th3_min = max(th2_c + 0.12, th3_c - 0.12); th3_max = min(3.7, th3_c + 0.12)\n",
        "g2 = np.arange(th2_min, th2_max + 1e-12, 0.005)\n",
        "g3 = np.arange(th3_min, th3_max + 1e-12, 0.005)\n",
        "best_q = -1.0; best_th = t0.copy()\n",
        "y_m = y[mask]; p_m = blend_oof[mask]\n",
        "for i, t2 in enumerate(g2):\n",
        "    for j, t3 in enumerate(g3):\n",
        "        if t3 - t2 < 0.12: continue\n",
        "        th_try = best_th.copy(); th_try[2] = t2; th_try[3] = t3\n",
        "        if th_try[1] >= th_try[2]: th_try[1] = max(th_try[1], th_try[2] - 0.12)\n",
        "        if th_try[0] >= th_try[1]: th_try[0] = max(0.3, th_try[1] - 0.12)\n",
        "        q = cohen_kappa_score(y_m, preds_to_classes(p_m, th_try), weights='quadratic')\n",
        "        if q > best_q: best_q = q; best_th = th_try.copy()\n",
        "    if (i+1) % 10 == 0:\n",
        "        print(f'grid row {i+1}/{len(g2)} best_q={best_q:.5f}', flush=True)\n",
        "\n",
        "print('2D grid (with ordinal) best OOF QWK:', f'{best_q:.5f}', 'best_th:', best_th, flush=True)\n",
        "\n",
        "# Apply to test and save\n",
        "cls = preds_to_classes(blend_te, best_th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_permodel_iso_nnls_withord_grid2d.npy', best_th); np.save('weights_permodel_iso_nnls_withord.npy', w)\n",
        "print('submission.csv written (top-5+ordinal per-model-iso + NNLS + 2D grid refine).', flush=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running top-5 + ordinal per-model isotonic + NNLS with 2D threshold refinement...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640', 'b5_ordinal'] weights: [0.3242 0.2596 0.2151 0.1329 0.0682 0.    ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 10/49 best_q=0.88690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 20/49 best_q=0.88882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 30/49 best_q=0.88941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 40/49 best_q=0.88941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D grid (with ordinal) best OOF QWK: 0.88941 best_th: [0.59176262 1.6049918  2.37433822 2.92947651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (top-5+ordinal per-model-iso + NNLS + 2D grid refine).\n"
          ]
        }
      ]
    },
    {
      "id": "fd25358c-046b-478d-8f54-b20112caed55",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Rank-averaged ensemble over up to 8 models + strict thresholding; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "print('Running rank-averaged ensemble over up to 8 models...', flush=True)\n",
        "\n",
        "keys = [\n",
        "    'b5_512_rrcema',\n",
        "    'serx50_512_rrcema',\n",
        "    'b5_512',\n",
        "    'b4_512',\n",
        "    'b4_640',\n",
        "    'r200d_512_rrcema',\n",
        "    'convnextb_512_rrcema',\n",
        "    'serx50_512_rrcema_s2',\n",
        "]\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "    'serx50_512_rrcema_s2': 'oof_preds_serx50_512_rrc_ema_seed2026.npy',\n",
        "    'r200d_512_rrcema': 'oof_preds_r200d_512_rrc_ema.npy',\n",
        "    'convnextb_512_rrcema': 'oof_preds_convnextb_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema_s2': ['test_reg_preds_serx50_512_rrc_ema_seed2026.npy'],\n",
        "    'r200d_512_rrcema': ['test_reg_preds_r200d_512_rrc_ema.npy'],\n",
        "    'convnextb_512_rrcema': ['test_reg_preds_convnextb_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Load arrays\n",
        "oof_list = []; te_list = []; used = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any(): continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    oof_list.append(a_oof); te_list.append(a_te); used.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable arrays for rank blend')\n",
        "print('Used keys:', used, flush=True)\n",
        "\n",
        "# Rank-transform to [0,4] using fractional ranks on OOF; apply same order for test per model\n",
        "def to_rank_scale(arr):\n",
        "    n = arr.shape[0]\n",
        "    order = np.argsort(arr)\n",
        "    ranks = np.empty_like(order, dtype=float)\n",
        "    ranks[order] = np.arange(n, dtype=float) / max(1, n-1)  # [0,1]\n",
        "    return ranks * 4.0\n",
        "\n",
        "rank_oof = []; rank_te = []\n",
        "for a_oof, a_te in zip(oof_list, te_list):\n",
        "    r_o = to_rank_scale(a_oof)\n",
        "    # Map test by interpolation based on OOF value->rank relation\n",
        "    # Use sorted pairs (x,y) from OOF and np.interp\n",
        "    xs = np.sort(a_oof)\n",
        "    ys = np.sort(r_o)\n",
        "    r_t = np.interp(a_te, xs, ys, left=ys[0], right=ys[-1])\n",
        "    rank_oof.append(r_o); rank_te.append(r_t)\n",
        "\n",
        "rank_oof = np.stack(rank_oof, axis=1)\n",
        "rank_te = np.stack(rank_te, axis=1)\n",
        "\n",
        "# Equal-weight rank mean (robust)\n",
        "blend_oof = rank_oof.mean(axis=1)\n",
        "blend_te = rank_te.mean(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "def optimize_thresholds_strict(y_true, p, init=[0.6,1.6,2.4,3.0]):\n",
        "    y_true = np.asarray(y_true).astype(float); p = np.asarray(p).astype(float)\n",
        "    def _loss(th):\n",
        "        th = np.sort(th); th = np.clip(th, 0.3, 3.7)\n",
        "        for i in range(1,4):\n",
        "            if th[i]-th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "        return -cohen_kappa_score(y_true, preds_to_classes(p, th), weights='quadratic')\n",
        "    res = minimize(_loss, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':1200, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    th = np.sort(res.x)\n",
        "    for i in range(1,4):\n",
        "        if th[i]-th[i-1] < 0.12: th[i] = th[i-1] + 0.12\n",
        "    th = np.clip(th, 0.3, 3.7)\n",
        "    return th\n",
        "\n",
        "mask = np.isfinite(y) & np.isfinite(blend_oof)\n",
        "th = optimize_thresholds_strict(y[mask], blend_oof[mask])\n",
        "q = cohen_kappa_score(y[mask], preds_to_classes(blend_oof[mask], th), weights='quadratic')\n",
        "print('Rank-mean OOF QWK:', f'{q:.5f}', 'th:', th, flush=True)\n",
        "\n",
        "# Write submission\n",
        "cls = preds_to_classes(blend_te, th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_rank_mean.npy', th)\n",
        "print('submission.csv written (rank-averaged ensemble).', flush=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running rank-averaged ensemble over up to 8 models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640', 'r200d_512_rrcema', 'convnextb_512_rrcema', 'serx50_512_rrcema_s2']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank-mean OOF QWK: 0.59607 th: [1.45973336 2.68771838 2.84911448 3.34870908]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (rank-averaged ensemble).\n"
          ]
        }
      ]
    },
    {
      "id": "fd020684-4f84-4316-a79d-b901d65640d7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Per-fold isotonic per model -> NNLS -> 2D (th2, th3) refine + th3 safety nudge; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running per-fold isotonic per model + NNLS + 2D refine with th3 safety nudge...', flush=True)\n",
        "\n",
        "# Config: top-5 models\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets and folds (assume order aligns with oof_targets.npy i.e., train.csv order)\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "folds_df = pd.read_csv('folds.csv')\n",
        "fold_arr = folds_df['fold'].values.astype(int)\n",
        "n_folds = int(fold_arr.max()) + 1\n",
        "if len(fold_arr) != len(y): raise RuntimeError('folds.csv length mismatch with OOF targets')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model per-fold isotonic calibration (robust to NaNs)\n",
        "cal_oof_list = []; cal_te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        print(f'Skip {k}: missing paths')\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te_base = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        print(f'Skip {k}: non-finite OOF')\n",
        "        continue\n",
        "    if not np.isfinite(a_te_base).all():\n",
        "        med = float(np.nanmedian(a_te_base[np.isfinite(a_te_base)]))\n",
        "        a_te_base = np.where(np.isfinite(a_te_base), a_te_base, med).astype(float)\n",
        "    # Build calibrated OOF with fold-wise transforms and average per-fold calibrated test\n",
        "    cal_oof = np.zeros_like(a_oof, dtype=float)\n",
        "    te_stack = []\n",
        "    finite_oof = np.isfinite(a_oof)\n",
        "    finite_y = np.isfinite(y)\n",
        "    for f in range(n_folds):\n",
        "        tr_mask = (fold_arr != f)\n",
        "        va_mask = (fold_arr == f)\n",
        "        tr_fit = tr_mask & finite_oof & finite_y\n",
        "        va_apply = va_mask & finite_oof\n",
        "        if tr_fit.sum() < 2 or va_apply.sum() == 0:\n",
        "            # Fallback: identity mapping for this fold\n",
        "            cal_oof[va_mask] = a_oof[va_mask]\n",
        "            te_stack.append(a_te_base.copy())\n",
        "            continue\n",
        "        ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "        ir.fit(a_oof[tr_fit], y[tr_fit])\n",
        "        # Transform only valid values for val; keep original where not finite\n",
        "        cal_fold = a_oof[va_mask].copy()\n",
        "        if va_apply.any():\n",
        "            cal_fold[va_apply[va_mask]] = ir.transform(a_oof[va_apply])\n",
        "        cal_oof[va_mask] = cal_fold\n",
        "        te_stack.append(ir.transform(a_te_base))\n",
        "    cal_te = np.mean(np.stack(te_stack, axis=0), axis=0) if len(te_stack) > 0 else a_te_base.copy()\n",
        "    # Final cleanup\n",
        "    cal_oof = np.where(np.isfinite(cal_oof), cal_oof, a_oof)\n",
        "    cal_oof = np.clip(cal_oof, 0.0, 4.0)\n",
        "    cal_te = np.clip(cal_te, 0.0, 4.0)\n",
        "    cal_oof_list.append(cal_oof); cal_te_list.append(cal_te); used_keys.append(k)\n",
        "\n",
        "if len(cal_oof_list) == 0: raise RuntimeError('No usable models after per-fold isotonic')\n",
        "print('Used keys:', used_keys, flush=True)\n",
        "\n",
        "# NNLS weights on calibrated OOF\n",
        "X = np.stack(cal_oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('NNLS weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(cal_te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# 2D refine around th2, th3 with min-gap 0.12, then safety nudge th3 +0.015 if within 0.0005 drop\n",
        "t0 = np.array([0.5918, 1.6050, 2.3743, 2.9295], dtype=float)\n",
        "try:\n",
        "    t_prev = np.load('thresholds_permodel_iso_nnls_grid2d.npy')\n",
        "    if getattr(t_prev, 'shape', None) == (4,): t0 = t_prev.astype(float)\n",
        "except Exception:\n",
        "    pass\n",
        "y_m = y[mask]; p_m = blend_oof[mask]\n",
        "th2_c, th3_c = float(t0[2]), float(t0[3])\n",
        "th2_min = max(0.6, th2_c - 0.12); th2_max = min(3.4, th2_c + 0.12)\n",
        "th3_min = max(th2_c + 0.12, th3_c - 0.12); th3_max = min(3.7, th3_c + 0.12)\n",
        "g2 = np.arange(th2_min, th2_max + 1e-12, 0.005)\n",
        "g3 = np.arange(th3_min, th3_max + 1e-12, 0.005)\n",
        "best_q = -1.0; best_th = t0.copy()\n",
        "for i, t2 in enumerate(g2):\n",
        "    for t3 in g3:\n",
        "        if t3 - t2 < 0.12: continue\n",
        "        th_try = best_th.copy(); th_try[2] = t2; th_try[3] = t3\n",
        "        if th_try[1] >= th_try[2]: th_try[1] = max(th_try[1], th_try[2] - 0.12)\n",
        "        if th_try[0] >= th_try[1]: th_try[0] = max(0.3, th_try[1] - 0.12)\n",
        "        q = cohen_kappa_score(y_m, preds_to_classes(p_m, th_try), weights='quadratic')\n",
        "        if q > best_q: best_q = q; best_th = th_try.copy()\n",
        "    if (i+1) % 10 == 0:\n",
        "        print(f'grid row {i+1}/{len(g2)} best_q={best_q:.5f}', flush=True)\n",
        "print('2D refine OOF QWK:', f'{best_q:.5f}', 'best_th:', best_th, flush=True)\n",
        "\n",
        "# Safety nudge th3 +0.015 if within 0.0005 drop\n",
        "th_safe = best_th.copy(); th_safe[3] = min(3.7, th_safe[3] + 0.015)\n",
        "q_safe = cohen_kappa_score(y_m, preds_to_classes(p_m, th_safe), weights='quadratic')\n",
        "chosen_th = th_safe if (best_q - q_safe) <= 0.0005 else best_th\n",
        "chosen_q = q_safe if (best_q - q_safe) <= 0.0005 else best_q\n",
        "print('Chosen OOF QWK:', f'{chosen_q:.5f}', 'chosen_th:', chosen_th, flush=True)\n",
        "\n",
        "# Apply to test and save submission\n",
        "cls = preds_to_classes(blend_te, chosen_th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_perfold_iso_nnls.npy', chosen_th); np.save('weights_perfold_iso_nnls.npy', w)\n",
        "print('submission.csv written (per-fold isotonic + NNLS + 2D refine + th3 nudge).', flush=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running per-fold isotonic per model + NNLS + 2D refine with th3 safety nudge...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS weights: [0.3532 0.1979 0.2314 0.1711 0.0464]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 10/49 best_q=0.87851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 20/49 best_q=0.87851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 30/49 best_q=0.87961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid row 40/49 best_q=0.87961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D refine OOF QWK: 0.87961 best_th: [0.59176262 1.6049918  2.39433822 2.99947651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen OOF QWK: 0.87950 chosen_th: [0.59176262 1.6049918  2.39433822 3.01447651]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (per-fold isotonic + NNLS + 2D refine + th3 nudge).\n"
          ]
        }
      ]
    },
    {
      "id": "ac0abe16-52dc-4b37-9b5b-258d7b36259f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Top-5 per-model isotonic + NNLS + 2D refine with th3 +0.015 safety nudge; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running top-5 per-model isotonic + NNLS + 2D refine with th3 safety nudge...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets_b4.npy', 'oof_targets.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float)\n",
        "        break\n",
        "if y is None:\n",
        "    raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Load arrays and fit per-model isotonic (global) for speed\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0:\n",
        "    raise RuntimeError('No usable models for per-model isotonic')\n",
        "\n",
        "print('Using keys:', used_keys, flush=True)\n",
        "\n",
        "# NNLS weights\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('NNLS weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Load previous best thresholds if exist; else from our best grid\n",
        "t0 = np.array([0.5918, 1.6050, 2.3743, 2.9295], dtype=float)\n",
        "for cand in ['thresholds_permodel_iso_nnls_grid2d.npy', 'thresholds_blend_nm.npy', 'thresholds_blend_isotonic.npy']:\n",
        "    if os.path.exists(cand):\n",
        "        tt = np.load(cand)\n",
        "        if getattr(tt, 'shape', None) == (4,):\n",
        "            t0 = tt.astype(float); break\n",
        "\n",
        "# Apply safety nudge +0.015 to th3 (clip), without re-optimizing on OOF\n",
        "t_nudge = t0.copy()\n",
        "t_nudge[3] = min(3.7, t_nudge[3] + 0.015)\n",
        "print('Applying th3 safety nudge: from', np.round(t0, 5), 'to', np.round(t_nudge, 5), flush=True)\n",
        "\n",
        "# Write submission\n",
        "cls = preds_to_classes(blend_te, t_nudge).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_permodel_iso_nnls_nudged.npy', t_nudge); np.save('weights_permodel_iso_nnls_top5.npy', w)\n",
        "print('submission.csv written (top-5 per-model-iso + NNLS + th3 +0.015 nudge).', flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running top-5 per-model isotonic + NNLS + 2D refine with th3 safety nudge...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying th3 safety nudge: from [0.59176 1.60499 2.37434 2.92948] to [0.59176 1.60499 2.37434 2.94448]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (top-5 per-model-iso + NNLS + th3 +0.015 nudge).\n"
          ]
        }
      ]
    },
    {
      "id": "9f8c10dd-9687-470c-84ed-e4a0299d83f7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Counts-based thresholding on best calibrated blend (top-5 per-model iso + NNLS); write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running counts-based thresholds on calibrated NNLS blend...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model global isotonic calibration\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable arrays for counts-based thresholding')\n",
        "print('Using keys:', used_keys, flush=True)\n",
        "\n",
        "# NNLS blend\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "print('NNLS weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Derive base class counts from OOF proportions using best thresholds if available\n",
        "t_base = None\n",
        "for cand in ['thresholds_permodel_iso_nnls_grid2d.npy', 'thresholds_permodel_iso_nnls.npy', 'thresholds_blend_nm.npy']:\n",
        "    if os.path.exists(cand):\n",
        "        tt = np.load(cand)\n",
        "        if getattr(tt, 'shape', None) == (4,):\n",
        "            t_base = tt.astype(float); break\n",
        "if t_base is None:\n",
        "    t_base = np.array([0.5918, 1.6050, 2.3743, 2.9295], dtype=float)\n",
        "\n",
        "# OOF class distribution under t_base\n",
        "cls_oof = preds_to_classes(blend_oof, t_base)\n",
        "counts_prop = np.bincount(cls_oof, minlength=5).astype(float) / max(1, len(cls_oof))\n",
        "n_test = int(pd.read_csv('test.csv').shape[0])\n",
        "counts_test = np.round(counts_prop * n_test).astype(int)\n",
        "diff = n_test - counts_test.sum()\n",
        "if diff != 0:\n",
        "    # Adjust the largest proportion classes to fix sum\n",
        "    order = np.argsort(-counts_prop)\n",
        "    i = 0\n",
        "    while diff != 0 and i < 5:\n",
        "        k = order[i]\n",
        "        counts_test[k] += 1 if diff > 0 else -1\n",
        "        diff = n_test - counts_test.sum()\n",
        "        if (diff == 0): break\n",
        "        i = (i + 1) % 5\n",
        "print('Target test counts:', counts_test.tolist(), flush=True)\n",
        "\n",
        "def thresholds_for_counts(scores, counts, min_gap=0.12):\n",
        "    scores = np.asarray(scores).astype(float)\n",
        "    s = np.sort(scores)\n",
        "    c = counts.astype(int)\n",
        "    idxs = [c[0]-1, c[0]+c[1]-1, c[0]+c[1]+c[2]-1, c[0]+c[1]+c[2]+c[3]-1]\n",
        "    th = []\n",
        "    for idx in idxs:\n",
        "        if idx < 0: th.append(s[0])\n",
        "        elif idx >= len(s): th.append(s[-1])\n",
        "        else: th.append(s[idx])\n",
        "    th = np.array(th, dtype=float)\n",
        "    # Enforce gaps by forward pass\n",
        "    th = np.clip(th, 0.3, 3.7)\n",
        "    for i in range(1,4):\n",
        "        if th[i] - th[i-1] < min_gap:\n",
        "            th[i] = min(3.7, th[i-1] + min_gap)\n",
        "    return th\n",
        "\n",
        "# Compute thresholds on TEST scores to match desired counts\n",
        "th_counts = thresholds_for_counts(blend_te, counts_test, min_gap=0.12)\n",
        "print('Counts-based thresholds:', np.round(th_counts, 5), flush=True)\n",
        "\n",
        "# Predict and write submission\n",
        "cls = preds_to_classes(blend_te, th_counts).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_counts_based.npy', th_counts); np.save('weights_counts_blend.npy', w)\n",
        "print('submission.csv written (counts-based thresholds).', flush=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running counts-based thresholds on calibrated NNLS blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target test counts: [107, 20, 63, 19, 158]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts-based thresholds: [0.3     0.42    0.83715 0.98371]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (counts-based thresholds).\n"
          ]
        }
      ]
    },
    {
      "id": "8100d9b9-5aaf-4bb7-970a-256feb0388b5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Brightness-binned thresholds on top-5 per-model isotonic + NNLS blend; write submission\n",
        "import os, numpy as np, pandas as pd, cv2, glob, time\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "t0 = time.time()\n",
        "print('Running brightness-binned thresholds on calibrated NNLS blend...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model global isotonic calibration\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable arrays for brightness-binned thresholding')\n",
        "print('Using keys:', used_keys, flush=True)\n",
        "\n",
        "# NNLS blend\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "print('NNLS weights:', np.round(w, 4), flush=True)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Load or compute brightness for train/test from cached 512px images\n",
        "def compute_brightness(img_paths):\n",
        "    vals = []\n",
        "    for i, p in enumerate(img_paths):\n",
        "        im = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n",
        "        if im is None:\n",
        "            vals.append(np.nan);\n",
        "        else:\n",
        "            vals.append(float(np.mean(im)))\n",
        "        if (i+1) % 500 == 0:\n",
        "            print(f'.. brightness {i+1}/{len(img_paths)}', flush=True)\n",
        "    v = np.array(vals, dtype=float)\n",
        "    # Handle NaNs by median fill\n",
        "    med = float(np.nanmedian(v)) if np.isfinite(v).any() else 128.0\n",
        "    v = np.where(np.isfinite(v), v, med)\n",
        "    return v\n",
        "\n",
        "# Train file order must match oof_targets.npy -> we assume it's train.csv order\n",
        "train_df = pd.read_csv('folds.csv')  # contains id_code in same order used for OOF\n",
        "train_ids = train_df['id_code'].values\n",
        "train_img_paths = [os.path.join('cache512/train', f'{i}.png') for i in train_ids]\n",
        "test_ids = pd.read_csv('test.csv')['id_code'].values\n",
        "test_img_paths = [os.path.join('cache512/test', f'{i}.png') for i in test_ids]\n",
        "\n",
        "bright_train = compute_brightness(train_img_paths)\n",
        "bright_test = compute_brightness(test_img_paths)\n",
        "\n",
        "# Define two bins by median train brightness\n",
        "thr_b = float(np.median(bright_train))\n",
        "bin0_tr = bright_train <= thr_b\n",
        "bin1_tr = ~bin0_tr\n",
        "bin0_te = bright_test <= thr_b\n",
        "bin1_te = ~bin0_te\n",
        "print('Brightness split @', thr_b, 'bin sizes train:', int(bin0_tr.sum()), int(bin1_tr.sum()), 'test:', int(bin0_te.sum()), int(bin1_te.sum()), flush=True)\n",
        "\n",
        "# Start from previous best thresholds if available\n",
        "t_base = np.array([0.5918, 1.6050, 2.3743, 2.9295], dtype=float)\n",
        "for cand in ['thresholds_permodel_iso_nnls_grid2d.npy', 'thresholds_permodel_iso_nnls.npy', 'thresholds_permodel_iso.npy']:\n",
        "    if os.path.exists(cand):\n",
        "        tt = np.load(cand)\n",
        "        if getattr(tt, 'shape', None) == (4,):\n",
        "            t_base = tt.astype(float); break\n",
        "\n",
        "def refine_2d(y_true, p, t0):\n",
        "    y_true = y_true.astype(float); p = p.astype(float)\n",
        "    m = np.isfinite(y_true) & np.isfinite(p)\n",
        "    y_m = y_true[m]; p_m = p[m]\n",
        "    th2_c, th3_c = float(t0[2]), float(t0[3])\n",
        "    th2_min = max(0.6, th2_c - 0.12); th2_max = min(3.4, th2_c + 0.12)\n",
        "    th3_min = max(th2_c + 0.12, th3_c - 0.12); th3_max = min(3.7, th3_c + 0.12)\n",
        "    g2 = np.arange(th2_min, th2_max + 1e-12, 0.005)\n",
        "    g3 = np.arange(th3_min, th3_max + 1e-12, 0.005)\n",
        "    best_q = -1.0; best_th = t0.copy()\n",
        "    for i, t2 in enumerate(g2):\n",
        "        for t3 in g3:\n",
        "            if t3 - t2 < 0.12: continue\n",
        "            th_try = best_th.copy(); th_try[2] = t2; th_try[3] = t3\n",
        "            if th_try[1] >= th_try[2]: th_try[1] = max(th_try[1], th_try[2] - 0.12)\n",
        "            if th_try[0] >= th_try[1]: th_try[0] = max(0.3, th_try[1] - 0.12)\n",
        "            q = cohen_kappa_score(y_m, preds_to_classes(p_m, th_try), weights='quadratic')\n",
        "            if q > best_q: best_q = q; best_th = th_try.copy()\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'.. grid row {i+1}/{len(g2)} best_q={best_q:.5f}', flush=True)\n",
        "    return best_th, best_q\n",
        "\n",
        "# Refine thresholds separately per brightness bin on OOF, then apply per-bin to test\n",
        "t0_bin0, q0 = refine_2d(y[bin0_tr], blend_oof[bin0_tr], t_base)\n",
        "t0_bin1, q1 = refine_2d(y[bin1_tr], blend_oof[bin1_tr], t_base)\n",
        "print('Bin0 OOF QWK candidate th:', np.round(t0_bin0, 5), 'Bin1:', np.round(t0_bin1, 5), flush=True)\n",
        "\n",
        "# Predict test per bin\n",
        "cls = np.zeros_like(blend_te, dtype=int)\n",
        "cls[bin0_te] = preds_to_classes(blend_te[bin0_te], t0_bin0)\n",
        "cls[bin1_te] = preds_to_classes(blend_te[bin1_te], t0_bin1)\n",
        "\n",
        "sub = pd.DataFrame({'id_code': test_ids, 'diagnosis': cls.astype(int)})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_brightness_bin0.npy', t0_bin0); np.save('thresholds_brightness_bin1.npy', t0_bin1); np.save('weights_permodel_iso_nnls_top5.npy', w)\n",
        "print('submission.csv written (brightness-binned thresholds). Elapsed: %.1fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running brightness-binned thresholds on calibrated NNLS blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. brightness 500/3295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. brightness 1000/3295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. brightness 1500/3295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. brightness 2000/3295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. brightness 2500/3295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. brightness 3000/3295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brightness split @ 127.6648178100586 bin sizes train: 1648 1647 test: 183 184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 10/49 best_q=0.87000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 20/49 best_q=0.87213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 30/49 best_q=0.87388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 40/49 best_q=0.87388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 10/49 best_q=0.89318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 20/49 best_q=0.89550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 30/49 best_q=0.89550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. grid row 40/49 best_q=0.89550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin0 OOF QWK candidate th: [0.59176 1.60499 2.37434 2.92948] Bin1: [0.59176 1.60499 2.32434 2.89948]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (brightness-binned thresholds). Elapsed: 32.8s\n"
          ]
        }
      ]
    },
    {
      "id": "0302b770-e6f5-4996-b7f8-673a5c7d29e0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Distribution alignment (quantile/CDF mapping) on best calibrated NNLS blend; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running distribution alignment on top-5 per-model iso + NNLS blend...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model isotonic calibration (global), then NNLS blend\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable arrays for distribution alignment')\n",
        "print('Using keys:', used_keys, flush=True)\n",
        "\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('NNLS weights:', np.round(w, 4), flush=True)\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "# Load best thresholds from 2D grid refine\n",
        "best_th = None\n",
        "for cand in ['thresholds_permodel_iso_nnls_grid2d.npy', 'thresholds_permodel_iso_nnls.npy']:\n",
        "    if os.path.exists(cand):\n",
        "        tt = np.load(cand)\n",
        "        if getattr(tt, 'shape', None) == (4,):\n",
        "            best_th = tt.astype(float); break\n",
        "if best_th is None:\n",
        "    best_th = np.array([0.59176262, 1.6049918, 2.37433822, 2.92947651], dtype=float)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Evaluate base OOF QWK with best_th\n",
        "y_m = y[mask]; p_m = blend_oof[mask]\n",
        "base_q = cohen_kappa_score(y_m, preds_to_classes(p_m, best_th), weights='quadratic')\n",
        "print('Base OOF QWK (no mapping):', f'{base_q:.5f}', 'th:', np.round(best_th,5), flush=True)\n",
        "\n",
        "# Fit monotonic mapping (isotonic) between sorted test preds and sorted OOF preds\n",
        "te_sorted = np.sort(blend_te)\n",
        "oof_sorted = np.sort(blend_oof[mask])\n",
        "iso_map = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "iso_map.fit(te_sorted, np.linspace(oof_sorted[0], oof_sorted[-1], num=len(te_sorted)))\n",
        "# Alternatively fit directly on sorted pairs (np.sort(blend_te), np.sort(blend_oof))\n",
        "# iso_map.fit(np.sort(blend_te), np.sort(blend_oof))\n",
        "\n",
        "blend_te_aligned = iso_map.transform(blend_te)\n",
        "blend_te_aligned = np.clip(blend_te_aligned, 0.0, 4.0)\n",
        "\n",
        "# Optional th3 safety nudge +0.015 if OOF drop <= 0.0005\n",
        "th_nudge = best_th.copy(); th_nudge[3] = min(3.7, th_nudge[3] + 0.015)\n",
        "q_nudge = cohen_kappa_score(y_m, preds_to_classes(p_m, th_nudge), weights='quadratic')\n",
        "chosen_th = th_nudge if (base_q - q_nudge) <= 0.0005 else best_th\n",
        "print('Safety nudge check: base_q=', f'{base_q:.5f}', 'q_nudge=', f'{q_nudge:.5f}', 'use_nudge=', (chosen_th is th_nudge), flush=True)\n",
        "\n",
        "# Predict classes on aligned test preds\n",
        "cls = preds_to_classes(blend_te_aligned, chosen_th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_dist_align.npy', chosen_th); np.save('weights_permodel_iso_nnLS_top5.npy', w)\n",
        "print('submission.csv written (distribution-aligned calibrated NNLS blend).', flush=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running distribution alignment on top-5 per-model iso + NNLS blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base OOF QWK (no mapping): 0.88941 th: [0.59176 1.60499 2.37434 2.92948]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Safety nudge check: base_q= 0.88941 q_nudge= 0.88941 use_nudge= True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (distribution-aligned calibrated NNLS blend).\n"
          ]
        }
      ]
    },
    {
      "id": "25242991-e7cf-4ac8-a9cc-fdef135a1872",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exact quantile mapping (empirical CDF alignment) on best calibrated NNLS blend; write submission\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from scipy.optimize import nnls\n",
        "\n",
        "print('Running exact quantile mapping on top-5 per-model iso + NNLS blend...', flush=True)\n",
        "\n",
        "keys = ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n",
        "paths_oof = {\n",
        "    'b4_512': 'oof_preds_b4.npy',\n",
        "    'b5_512': 'oof_preds.npy',\n",
        "    'b5_512_rrcema': 'oof_preds_b5_seed2025_rrc_ema.npy',\n",
        "    'b4_640': 'oof_preds_b4_640_rrc_ema.npy',\n",
        "    'serx50_512_rrcema': 'oof_preds_serx50_512_rrc_ema.npy',\n",
        "}\n",
        "paths_te_opts = {\n",
        "    'b4_512': ['test_reg_preds_b4_hflip.npy', 'test_reg_preds_b4.npy'],\n",
        "    'b5_512': ['test_reg_preds_b5_hflip.npy', 'test_reg_preds.npy'],\n",
        "    'b5_512_rrcema': ['test_reg_preds_b5_seed2025_rrc_ema.npy'],\n",
        "    'b4_640': ['test_reg_preds_b4_640_rrc_ema.npy'],\n",
        "    'serx50_512_rrcema': ['test_reg_preds_serx50_512_rrc_ema.npy'],\n",
        "}\n",
        "\n",
        "# Targets\n",
        "y = None\n",
        "for tgt in ['oof_targets.npy', 'oof_targets_b4.npy']:\n",
        "    if os.path.exists(tgt):\n",
        "        y = np.load(tgt).reshape(-1).astype(float); break\n",
        "if y is None: raise RuntimeError('OOF targets not found')\n",
        "\n",
        "# Resolve test paths\n",
        "paths_te = {}\n",
        "for k in keys:\n",
        "    for p in paths_te_opts.get(k, []):\n",
        "        if os.path.exists(p):\n",
        "            paths_te[k] = p; break\n",
        "\n",
        "# Per-model global isotonic calibration\n",
        "oof_list = []; te_list = []; used_keys = []\n",
        "for k in keys:\n",
        "    po = paths_oof.get(k, None); pt = paths_te.get(k, None)\n",
        "    if po is None or (not os.path.exists(po)) or pt is None or (not os.path.exists(pt)):\n",
        "        continue\n",
        "    a_oof = np.load(po).reshape(-1).astype(float)\n",
        "    a_te = np.load(pt).reshape(-1).astype(float)\n",
        "    if not np.isfinite(a_oof).any():\n",
        "        continue\n",
        "    if not np.isfinite(a_te).all():\n",
        "        med = float(np.nanmedian(a_te[np.isfinite(a_te)]))\n",
        "        a_te = np.where(np.isfinite(a_te), a_te, med).astype(float)\n",
        "    mask_fit = np.isfinite(y) & np.isfinite(a_oof)\n",
        "    ir = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    ir.fit(a_oof[mask_fit], y[mask_fit])\n",
        "    cal_o = a_oof.copy(); cal_o[mask_fit] = ir.transform(a_oof[mask_fit])\n",
        "    cal_o = np.where(np.isfinite(cal_o), cal_o, a_oof); cal_o = np.clip(cal_o, 0.0, 4.0)\n",
        "    cal_t = ir.transform(a_te); cal_t = np.clip(cal_t, 0.0, 4.0)\n",
        "    oof_list.append(cal_o); te_list.append(cal_t); used_keys.append(k)\n",
        "\n",
        "if len(oof_list) == 0: raise RuntimeError('No usable arrays for quantile mapping')\n",
        "print('Using keys:', used_keys, flush=True)\n",
        "\n",
        "# NNLS blend\n",
        "X = np.stack(oof_list, axis=1)\n",
        "mask = np.isfinite(y) & np.isfinite(X).all(axis=1)\n",
        "A = X[mask]; b = y[mask]\n",
        "w_raw, _ = nnls(A, b)\n",
        "w = w_raw / (w_raw.sum() if w_raw.sum() > 0 else len(w_raw))\n",
        "print('NNLS weights:', np.round(w, 4), flush=True)\n",
        "blend_oof = (X * w.reshape(1, -1)).sum(axis=1)\n",
        "te_stack = np.stack(te_list, axis=1)\n",
        "blend_te = (te_stack * w.reshape(1, -1)).sum(axis=1)\n",
        "\n",
        "# Load best thresholds\n",
        "best_th = None\n",
        "for cand in ['thresholds_permodel_iso_nnls_grid2d.npy', 'thresholds_permodel_iso_nnls.npy']:\n",
        "    if os.path.exists(cand):\n",
        "        tt = np.load(cand)\n",
        "        if getattr(tt, 'shape', None) == (4,):\n",
        "            best_th = tt.astype(float); break\n",
        "if best_th is None:\n",
        "    best_th = np.array([0.59176262, 1.6049918, 2.37433822, 2.92947651], dtype=float)\n",
        "\n",
        "def preds_to_classes(p, th):\n",
        "    return np.digitize(p, bins=[th[0], th[1], th[2], th[3]])\n",
        "\n",
        "# Base OOF QWK for reference\n",
        "y_m = y[mask]; p_m = blend_oof[mask]\n",
        "base_q = cohen_kappa_score(y_m, preds_to_classes(p_m, best_th), weights='quadratic')\n",
        "print('Base OOF QWK (no mapping):', f'{base_q:.5f}', 'th:', np.round(best_th,5), flush=True)\n",
        "\n",
        "# Exact quantile mapping: map test ranks r in [0,1] to OOF empirical CDF\n",
        "oof_sorted = np.sort(p_m)\n",
        "n_te = len(blend_te); n_oof = len(oof_sorted)\n",
        "r = np.argsort(np.argsort(blend_te)).astype(float)\n",
        "r = r / max(1.0, n_te - 1)  # ranks in [0,1]\n",
        "q_grid = np.linspace(0.0, 1.0, num=n_oof)\n",
        "blend_te_aligned = np.interp(r, q_grid, oof_sorted)\n",
        "blend_te_aligned = np.clip(blend_te_aligned, 0.0, 4.0)\n",
        "\n",
        "# Safety nudge +0.015 on th3 if OOF drop <= 0.0005\n",
        "th_nudge = best_th.copy(); th_nudge[3] = min(3.7, th_nudge[3] + 0.015)\n",
        "q_nudge = cohen_kappa_score(y_m, preds_to_classes(p_m, th_nudge), weights='quadratic')\n",
        "chosen_th = th_nudge if (base_q - q_nudge) <= 0.0005 else best_th\n",
        "print('Safety nudge check: base_q=', f'{base_q:.5f}', 'q_nudge=', f'{q_nudge:.5f}', 'use_nudge=', (chosen_th is th_nudge), flush=True)\n",
        "\n",
        "# Predict and save\n",
        "cls = preds_to_classes(blend_te_aligned, chosen_th).astype(int)\n",
        "sub = pd.DataFrame({'id_code': pd.read_csv('test.csv')['id_code'].values, 'diagnosis': cls})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "np.save('thresholds_dist_align_quantile.npy', chosen_th); np.save('weights_permodel_iso_nnls_top5.npy', w)\n",
        "print('submission.csv written (exact quantile-aligned calibrated NNLS blend).', flush=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running exact quantile mapping on top-5 per-model iso + NNLS blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using keys: ['b5_512_rrcema', 'serx50_512_rrcema', 'b5_512', 'b4_512', 'b4_640']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NNLS weights: [0.3242 0.2596 0.2151 0.1329 0.0682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base OOF QWK (no mapping): 0.88941 th: [0.59176 1.60499 2.37434 2.92948]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Safety nudge check: base_q= 0.88941 q_nudge= 0.88941 use_nudge= True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written (exact quantile-aligned calibrated NNLS blend).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}