{
  "cells": [
    {
      "id": "0f1de352-b01a-4e68-a8c5-880e10c04313",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# APTOS 2019 Blindness Detection \u2014 Medal Plan & Experiment Log\n",
        "\n",
        "Objective: Train an image model to predict diabetic retinopathy grade (0\u20134) on fundus images. Metric: Quadratic Weighted Kappa (QWK). Deliver submission.csv and iterate to medal.\n",
        "\n",
        "Success gates:\n",
        "- Bronze \u2265 0.9145\n",
        "- Silver \u2265 0.9197\n",
        "- Gold \u2265 0.9305\n",
        "\n",
        "Metric quirks:\n",
        "- Ordinal classes; misordering penalized more than close misses. QWK sensitive to calibration/thresholds.\n",
        "\n",
        "Validation protocol (lock early):\n",
        "- 5-fold StratifiedKFold by diagnosis with fixed seed\n",
        "- Save and reuse exact fold indices across experiments (deterministic CV)\n",
        "- Deterministic: set seeds (python, numpy, torch, cudnn), fix worker seeds\n",
        "- Track OOF predictions and compute QWK per fold + overall; early stop on QWK\n",
        "\n",
        "Mandatory preprocessing (apply to train/val/test):\n",
        "- Circular crop of fundus (remove black borders)\n",
        "- Brightness/contrast normalization: Ben Graham/CLAHE, optional color constancy\n",
        "- Center and resize to target resolution; avoid vertical flips\n",
        "\n",
        "Baseline plan (fast to strong):\n",
        "1) Sanity checks + GPU test\n",
        "2) Data load + EDA: class balance, image dims, sample visual checks of preprocessing\n",
        "3) Minimal baseline (pipeline validation): EfficientNet-B0/224, REGRESSION head (1 out), MSELoss, AdamW, cosine LR, AMP, 5-fold, 2\u20133 epochs on subset\n",
        "4) Threshold optimization on OOF (Nelder\u2013Mead/coordinate descent, 4 cutpoints) for QWK; apply fixed thresholds to test; submit\n",
        "5) Stronger model @512: EfficientNet-B3 or EfficientNetV2-S, augmentations (HF only, \u00b115\u00b0 rotate, scale/zoom, brightness/contrast/gamma, light blur; no VF/90\u00b0), class weights or sampler, EMA\n",
        "6) TTA (orig + hflip) and resolution/seed sweep; retrain with early stopping on QWK\n",
        "7) Ensembling: 2\u20133 diverse models/seeds; average regression outputs; re-opt thresholds on blended OOF\n",
        "\n",
        "Risk controls:\n",
        "- Install torch + timm; test CUDA first. Start with tiny subset to avoid long broken runs.\n",
        "- Early stopping, save best QWK per fold; log OOF and thresholds to disk.\n",
        "- Keep notebook concise; delete stale cells after logging.\n",
        "\n",
        "Deliverables:\n",
        "- submission.csv (id_code, diagnosis)\n",
        "- Reproducible CV with OOF QWK tracked and thresholds saved\n",
        "\n",
        "Experiment Log:\n",
        "| Exp | Model/Res | Loss | Aug | Folds/Seeds | OOF QWK | LB QWK | Notes |\n",
        "|-----|-----------|------|-----|-------------|---------|--------|-------|\n",
        "|     |           |      |     |             |         |        |       |\n",
        "\n",
        "Next step: GPU test, package installs, implement fundus crop + normalization, and data load."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "52e827c2-58d0-4477-9fb8-3f6d75ec13d9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, subprocess, importlib, os\n",
        "def ensure(pkg, pip_name=None):\n",
        "    pip_name = pip_name or pkg\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "        print(f\"OK: {pkg} already installed\")\n",
        "    except Exception as e:\n",
        "        print(f\"Installing {pip_name}...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', pip_name, '-q'], check=False)\n",
        "        importlib.import_module(pkg)\n",
        "\n",
        "# Core deps\n",
        "ensure('pandas')\n",
        "ensure('numpy')\n",
        "ensure('scipy')\n",
        "ensure('sklearn', 'scikit-learn')\n",
        "ensure('tqdm')\n",
        "ensure('cv2', 'opencv-python-headless')\n",
        "ensure('albumentations')\n",
        "\n",
        "# PyTorch + vision + timm (CUDA 12.1 wheels)\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "except Exception:\n",
        "    print('Installing torch/torchvision for CUDA 12.1...')\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch', 'torchvision', '-q'], check=False)\n",
        "    import torch, torchvision\n",
        "ensure('timm')\n",
        "\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"GPU Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "import pandas as pd\n",
        "train_path, test_path = 'train.csv', 'test.csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "print('Train shape:', train_df.shape, 'Test shape:', test_df.shape)\n",
        "print('Train head:')\n",
        "print(train_df.head())\n",
        "if 'diagnosis' in train_df.columns:\n",
        "    print('Diagnosis distribution:')\n",
        "    print(train_df['diagnosis'].value_counts().sort_index())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "91998fbc-d305-44bb-b2f2-d9f2c9c7ff42",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from typing import Tuple\n",
        "\n",
        "def robust_circular_crop(img: np.ndarray) -> np.ndarray:\n",
        "    h, w = img.shape[:2]\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.medianBlur(gray, 11)\n",
        "    # Otsu threshold\n",
        "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # Sometimes Otsu picks background as fg; choose better of mask / inverted by largest contour area\n",
        "    def largest_area(m):\n",
        "        cnts, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        return 0 if not cnts else max(cv2.contourArea(c) for c in cnts)\n",
        "    area1 = largest_area(mask)\n",
        "    area2 = largest_area(255 - mask)\n",
        "    if area2 > area1:\n",
        "        mask = 255 - mask\n",
        "    # Morph open to clean noise\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not cnts:\n",
        "        # Fallback: center square crop\n",
        "        side = min(h, w)\n",
        "        y0 = (h - side) // 2\n",
        "        x0 = (w - side) // 2\n",
        "        return img[y0:y0+side, x0:x0+side]\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    (x, y), r = cv2.minEnclosingCircle(c)\n",
        "    x, y, r = int(x), int(y), int(r)\n",
        "    # sanity: if radius too small, fallback to center crop\n",
        "    if r < min(h, w) * 0.2:\n",
        "        side = min(h, w)\n",
        "        y0 = (h - side) // 2\n",
        "        x0 = (w - side) // 2\n",
        "        return img[y0:y0+side, x0:x0+side]\n",
        "    x1, y1 = max(0, x - r), max(0, y - r)\n",
        "    x2, y2 = min(w, x + r), min(h, y + r)\n",
        "    crop = img[y1:y2, x1:x2]\n",
        "    return crop if crop.size else img\n",
        "\n",
        "def ben_graham_normalize(img: np.ndarray, sigma: int = 30) -> np.ndarray:\n",
        "    # Apply on fixed-size image with fixed sigma\n",
        "    blur = cv2.GaussianBlur(img, (0, 0), sigma)\n",
        "    enhanced = cv2.addWeighted(img, 4, blur, -4, 128)\n",
        "    return np.clip(enhanced, 0, 255).astype(np.uint8)\n",
        "\n",
        "def preprocess_fundus(img: np.ndarray, out_size: int = 512, use_ben: bool = True) -> np.ndarray:\n",
        "    # 1) robust circular crop\n",
        "    img = robust_circular_crop(img)\n",
        "    # 2) resize to fixed size\n",
        "    img = cv2.resize(img, (out_size, out_size), interpolation=cv2.INTER_AREA)\n",
        "    # 3) illumination normalization (Ben Graham)\n",
        "    if use_ben:\n",
        "        img = ben_graham_normalize(img, sigma=30)\n",
        "    return img\n",
        "\n",
        "def read_preprocess(image_id: str, root: str, out_size: int = 512) -> np.ndarray:\n",
        "    path = os.path.join(root, f\"{image_id}.png\")\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(path)\n",
        "    img = preprocess_fundus(img, out_size=out_size, use_ben=True)\n",
        "    return img\n",
        "\n",
        "# Quick dry-run on a few samples to validate shapes and visualize before/after:\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    # pick up to 2 samples per class for visual check\n",
        "    ids = []\n",
        "    for cls in sorted(train_df['diagnosis'].unique()):\n",
        "        ids += train_df[train_df['diagnosis'] == cls]['id_code'].head(2).tolist()\n",
        "    ids = ids[:8] if len(ids) > 8 else ids\n",
        "    print('Visual check IDs:', ids)\n",
        "    n = len(ids)\n",
        "    fig, axes = plt.subplots(n, 2, figsize=(6, 3*n))\n",
        "    if n == 1:\n",
        "        axes = np.array([axes])\n",
        "    for i, iid in enumerate(ids):\n",
        "        p = os.path.join('train_images', f'{iid}.png')\n",
        "        orig = cv2.imread(p, cv2.IMREAD_COLOR)\n",
        "        proc = preprocess_fundus(orig.copy(), out_size=512, use_ben=True)\n",
        "        # BGR->RGB for display\n",
        "        orig_rgb = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
        "        proc_rgb = cv2.cvtColor(proc, cv2.COLOR_BGR2RGB)\n",
        "        axes[i, 0].imshow(orig_rgb); axes[i, 0].set_title(f'{iid} orig'); axes[i, 0].axis('off')\n",
        "        axes[i, 1].imshow(proc_rgb); axes[i, 1].set_title('processed'); axes[i, 1].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    # Print basic stats to confirm dtype/range\n",
        "    for iid in ids[:3]:\n",
        "        arr = read_preprocess(iid, 'train_images', out_size=512)\n",
        "        print(iid, arr.shape, arr.dtype, arr.min(), arr.max())\n",
        "except Exception as e:\n",
        "    print('Preprocessing validation error:', e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b7c97e84-b832-4894-a8f6-04df7953f207",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, random, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Reuse preprocess from cell 2\n",
        "from pathlib import Path\n",
        "\n",
        "SEED = 42\n",
        "FOLDS = 5\n",
        "OUT_SIZE = 512\n",
        "FOLD_FILE = f'folds_s{SEED}_k{FOLDS}.csv'\n",
        "CACHE_DIR = Path(f'cache_{OUT_SIZE}')\n",
        "\n",
        "def seed_everything(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    try:\n",
        "        import torch\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "seed_everything(SEED)\n",
        "\n",
        "# Create/reuse CV folds\n",
        "train_df = pd.read_csv('train.csv')\n",
        "if os.path.exists(FOLD_FILE):\n",
        "    folds_df = pd.read_csv(FOLD_FILE)\n",
        "    print('Loaded existing folds:', FOLD_FILE)\n",
        "else:\n",
        "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
        "    fold_idx = np.zeros(len(train_df), dtype=int) - 1\n",
        "    for f, (_, val_idx) in enumerate(skf.split(train_df['id_code'], train_df['diagnosis'])):\n",
        "        fold_idx[val_idx] = f\n",
        "    folds_df = train_df.copy()\n",
        "    folds_df['fold'] = fold_idx\n",
        "    folds_df.to_csv(FOLD_FILE, index=False)\n",
        "    print('Saved folds to', FOLD_FILE)\n",
        "\n",
        "# Weighted sampler weights (1/sqrt(n_class)) to save for later\n",
        "vc = folds_df['diagnosis'].value_counts().to_dict()\n",
        "class_weights = {k: 1.0 / np.sqrt(v) for k, v in vc.items()}\n",
        "with open('class_weights.json', 'w') as f:\n",
        "    json.dump(class_weights, f)\n",
        "print('Class weights:', class_weights)\n",
        "\n",
        "# Cache preprocessed images (train + test) to speed up IO\n",
        "train_src = Path('train_images')\n",
        "test_src = Path('test_images')\n",
        "train_dst = CACHE_DIR / 'train'\n",
        "test_dst = CACHE_DIR / 'test'\n",
        "train_dst.mkdir(parents=True, exist_ok=True)\n",
        "test_dst.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def cache_split(df, src_dir: Path, dst_dir: Path):\n",
        "    for iid in tqdm(df['id_code'].tolist(), desc=f'Caching to {dst_dir}'):\n",
        "        outp = dst_dir / f'{iid}.png'\n",
        "        if outp.exists():\n",
        "            continue\n",
        "        try:\n",
        "            img = read_preprocess(iid, str(src_dir), out_size=OUT_SIZE)\n",
        "            cv2.imwrite(str(outp), img)\n",
        "        except Exception as e:\n",
        "            print('Error caching', iid, e)\n",
        "\n",
        "cache_split(train_df, train_src, train_dst)\n",
        "test_df = pd.read_csv('test.csv')\n",
        "cache_split(test_df, test_src, test_dst)\n",
        "print('Caching complete:', train_dst, test_dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "234ba924-4fa9-47b6-857b-2b9211d86226",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, numpy as np, pandas as pd, torch, timm, cv2\n",
        "from pathlib import Path\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.swa_utils import AveragedModel\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "CACHE_DIR_512 = Path('cache_512/test')\n",
        "TEST_DF = pd.read_csv('test.csv')\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms_for_size(size):\n",
        "    return A.Compose([A.Resize(size, size), A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD), ToTensorV2()])\n",
        "\n",
        "class CacheTestDS(Dataset):\n",
        "    def __init__(self, df, img_dir: Path, size: int):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.tfm = get_transforms_for_size(size)\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / f\"{row['id_code']}.png\"\n",
        "        img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfm(image=img)['image']\n",
        "        return x, -1.0\n",
        "\n",
        "def load_b0_model(ckpt_path: str):\n",
        "    model = timm.create_model('tf_efficientnet_b0_ns', pretrained=False, num_classes=1)\n",
        "    model = model.to(DEVICE).to(memory_format=torch.channels_last)\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)\n",
        "    model.load_state_dict(ckpt['model'], strict=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def load_b3_ema_model(ckpt_path: str):\n",
        "    base = timm.create_model('tf_efficientnet_b3_ns', pretrained=False, num_classes=1)\n",
        "    base = base.to(DEVICE).to(memory_format=torch.channels_last)\n",
        "    ema = AveragedModel(base)\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)\n",
        "    ema.load_state_dict(ckpt['model'], strict=True)\n",
        "    ema.eval()\n",
        "    return ema\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer_models(model_specs):\n",
        "    # model_specs: list of dicts {path, kind ('b0'|'b3'), size}\n",
        "    all_preds = []\n",
        "    for spec in model_specs:\n",
        "        size = spec['size']\n",
        "        ds = CacheTestDS(TEST_DF, CACHE_DIR_512, size=size)\n",
        "        loader = DataLoader(ds, batch_size=2, shuffle=False, num_workers=0, pin_memory=True)\n",
        "        if spec['kind'] == 'b0':\n",
        "            model = load_b0_model(spec['path'])\n",
        "        else:\n",
        "            model = load_b3_ema_model(spec['path'])\n",
        "        preds = []\n",
        "        for xb, _ in loader:\n",
        "            xb = xb.to(DEVICE, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
        "            xb_flip = torch.flip(xb, dims=[3])\n",
        "            with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "                p1 = model(xb).squeeze(1).float()\n",
        "                p2 = model(xb_flip).squeeze(1).float()\n",
        "                p = 0.5 * (p1 + p2)\n",
        "            preds.append(p.detach().cpu().numpy())\n",
        "        all_preds.append(np.concatenate(preds))\n",
        "        del model; torch.cuda.empty_cache()\n",
        "    return np.mean(np.stack(all_preds, axis=0), axis=0)\n",
        "\n",
        "def apply_thresholds(preds, cuts):\n",
        "    t = np.sort(np.asarray(cuts).astype(float))\n",
        "    y = np.digitize(preds, t)\n",
        "    return np.clip(y, 0, 4).astype(int)\n",
        "\n",
        "# Assemble available checkpoints\n",
        "model_specs = []\n",
        "# b3@512 folds 0-1 (EMA checkpoints present)\n",
        "if os.path.exists('models/b3_512_reg_v1_fold0.pt'):\n",
        "    model_specs.append({'path': 'models/b3_512_reg_v1_fold0.pt', 'kind': 'b3', 'size': 512})\n",
        "if os.path.exists('models/b3_512_reg_v1_fold1.pt'):\n",
        "    model_specs.append({'path': 'models/b3_512_reg_v1_fold1.pt', 'kind': 'b3', 'size': 512})\n",
        "# b0@512 folds 0-4\n",
        "for f in range(5):\n",
        "    p = f'models/b0_512_reg_v1_fold{f}.pt'\n",
        "    if os.path.exists(p):\n",
        "        model_specs.append({'path': p, 'kind': 'b0', 'size': 512})\n",
        "\n",
        "assert len(model_specs) > 0, 'No ensemble checkpoints found.'\n",
        "print('Ensembling models:', model_specs)\n",
        "\n",
        "blended_preds = infer_models(model_specs)\n",
        "with open('thresholds_b0_512_reg_v1.json', 'r') as fh:\n",
        "    th = json.load(fh)['cuts']\n",
        "labels = apply_thresholds(blended_preds, th)\n",
        "sub = pd.DataFrame({'id_code': TEST_DF['id_code'], 'diagnosis': labels})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv', sub.shape, 'using ensemble of', len(model_specs), 'models')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c09cdb7f-27c6-41a8-91ed-08e197f27159",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, numpy as np, pandas as pd, cv2, torch, timm\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.optim.swa_utils import AveragedModel\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "EXP_NAME = 'b3_384_reg_v2'\n",
        "MODEL_NAME = 'tf_efficientnet_b3_ns'\n",
        "TEST_DF = pd.read_csv('test.csv')\n",
        "CACHE_DIR = Path('cache_512/test')\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_test_tfm(size=384):\n",
        "    return A.Compose([A.Resize(size, size), A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD), ToTensorV2()])\n",
        "\n",
        "class CacheTestDS(Dataset):\n",
        "    def __init__(self, df, img_dir: Path, size: int = 384):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.tfm = get_test_tfm(size)\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        p = self.img_dir / f\"{row['id_code']}.png\"\n",
        "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(str(p))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfm(image=img)['image']\n",
        "        return x, -1.0\n",
        "\n",
        "@torch.no_grad()\n",
        "def infer_fold(ckpt_path: str, batch_size: int = 2, size: int = 384):\n",
        "    ds = CacheTestDS(TEST_DF, CACHE_DIR, size=size)\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    base = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "    ema = AveragedModel(base)\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)\n",
        "    ema.load_state_dict(ckpt['model'], strict=True)\n",
        "    ema.eval()\n",
        "    preds = []\n",
        "    for xb, _ in loader:\n",
        "        out = ema(xb).squeeze(1).float()\n",
        "        preds.append(out.detach().cpu().numpy())\n",
        "    return np.concatenate(preds)\n",
        "\n",
        "def apply_thresholds(preds, cuts):\n",
        "    t = np.sort(np.asarray(cuts).astype(float))\n",
        "    y = np.digitize(preds, t)\n",
        "    return np.clip(y, 0, 4).astype(int)\n",
        "\n",
        "def optimize_thresholds(preds, targets, init=[0.5,1.5,2.5,3.5]):\n",
        "    preds = np.asarray(preds).ravel().astype(float)\n",
        "    targets = np.asarray(targets).ravel().astype(int)\n",
        "    def neg_qwk(c):\n",
        "        from sklearn.metrics import cohen_kappa_score\n",
        "        y = apply_thresholds(preds, c)\n",
        "        return -cohen_kappa_score(targets, y, weights='quadratic')\n",
        "    res = minimize(neg_qwk, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':500, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    return np.sort(res.x).tolist()\n",
        "\n",
        "# Collect fold checkpoints\n",
        "fold_paths = [f'models/{EXP_NAME}_fold{f}.pt' for f in range(5) if os.path.exists(f'models/{EXP_NAME}_fold{f}.pt')]\n",
        "assert len(fold_paths) > 0, 'No trained fold checkpoints found for b3_384_reg_v2.'\n",
        "print('Found fold checkpoints:', fold_paths)\n",
        "\n",
        "# Inference per fold on CPU, then average\n",
        "fold_preds = [infer_fold(p, batch_size=2, size=384) for p in fold_paths]\n",
        "test_preds = np.mean(np.stack(fold_preds, axis=0), axis=0)\n",
        "print('Test preds shape:', test_preds.shape)\n",
        "\n",
        "# Optimize thresholds on OOF and save\n",
        "oof_preds_path = f'oof/{EXP_NAME}_oof_preds.npy'\n",
        "oof_tgts_path = f'oof/{EXP_NAME}_oof_targets.npy'\n",
        "assert os.path.exists(oof_preds_path) and os.path.exists(oof_tgts_path), 'OOF files not found.'\n",
        "oof_preds = np.load(oof_preds_path)\n",
        "oof_tgts = np.load(oof_tgts_path)\n",
        "cuts = optimize_thresholds(oof_preds, oof_tgts)\n",
        "with open(f'thresholds_{EXP_NAME}.json', 'w') as fh:\n",
        "    json.dump({'cuts': cuts}, fh)\n",
        "print('Optimized thresholds:', cuts)\n",
        "\n",
        "# Make submission\n",
        "labels = apply_thresholds(test_preds, cuts)\n",
        "sub = pd.DataFrame({'id_code': TEST_DF['id_code'], 'diagnosis': labels})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv', sub.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c5a1f9cd-a9a6-41dc-8ee6-c9d075fc6835",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity check: train a single fold with shorter schedule to verify stability before full CV\n",
        "import pandas as pd, time\n",
        "folds_df = pd.read_csv('folds_s42_k5.csv')\n",
        "\n",
        "# Temporarily reduce epochs/patience for quick validation\n",
        "NUM_EPOCHS = 10\n",
        "MIN_EPOCHS = 6\n",
        "PATIENCE = 5\n",
        "\n",
        "start = time.time()\n",
        "oof_pred, y_val, ckpt_path = train_one_fold(0, folds_df)\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import numpy as np\n",
        "cuts, _ = optimize_thresholds(oof_pred, y_val)\n",
        "y_round = apply_thresholds(oof_pred, cuts)\n",
        "q_naive = cohen_kappa_score(y_val.astype(int), np.clip(np.rint(oof_pred), 0, 4).astype(int), weights='quadratic')\n",
        "q_opt = cohen_kappa_score(y_val.astype(int), y_round.astype(int), weights='quadratic')\n",
        "print('Sanity Fold0: QWK naive/opt:', q_naive, q_opt, 'pred_mean/std:', float(np.mean(oof_pred)), float(np.std(oof_pred)), 'ckpt:', ckpt_path)\n",
        "print(f'Wall-clock: {(time.time()-start)/60:.1f} min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d2dd54f2-9977-449b-9bdb-bb50a2ea45b6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity check for ordinal pipeline: train a single fold briefly and report QWK\n",
        "import time, pandas as pd, numpy as np\n",
        "folds_df = pd.read_csv('folds_s42_k5.csv')\n",
        "\n",
        "# Short schedule for sanity\n",
        "NUM_EPOCHS = 8\n",
        "ACCUM_STEPS = 16\n",
        "\n",
        "t0 = time.time()\n",
        "preds_ord, y_val, best_path = train_one_fold(0, folds_df)\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "q = cohen_kappa_score(y_val, preds_ord, weights='quadratic')\n",
        "print(f'Sanity Fold0 (ordinal): QWK={q:.4f}, preds dist:', np.bincount(preds_ord, minlength=5), 'path:', best_path)\n",
        "print(f'Wall-clock: {(time.time()-t0)/60:.1f} min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3a45ae42-679f-4fff-9567-28784d4a4a4d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal, clean baseline: EfficientNet-B0 @512 regression, single-fold sanity run (FP32, no AMP/EMA/schedulers)\n",
        "import os, time, json, numpy as np, pandas as pd, cv2, torch, timm\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "CACHE_DIR = Path('cache_512/train')\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def qwk(y_true, y_pred):\n",
        "    return cohen_kappa_score(np.asarray(y_true).astype(int), np.asarray(y_pred).astype(int), weights='quadratic')\n",
        "\n",
        "def apply_thresholds(preds, cuts):\n",
        "    t = np.sort(np.asarray(cuts).astype(float))\n",
        "    y = np.digitize(preds, t)\n",
        "    return np.clip(y, 0, 4).astype(int)\n",
        "\n",
        "def optimize_thresholds(preds, targets, init=[0.5,1.5,2.5,3.5]):\n",
        "    from scipy.optimize import minimize\n",
        "    preds = np.asarray(preds).ravel().astype(float)\n",
        "    targets = np.asarray(targets).ravel().astype(int)\n",
        "    def neg_qwk(c):\n",
        "        y = apply_thresholds(preds, c)\n",
        "        return -qwk(targets, y)\n",
        "    res = minimize(neg_qwk, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':400, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    return np.sort(res.x)\n",
        "\n",
        "class CacheDS(Dataset):\n",
        "    def __init__(self, df, img_dir: Path, train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.train = train\n",
        "        self.tfm = A.Compose([\n",
        "            A.Resize(512, 512),\n",
        "            A.HorizontalFlip(p=0.5 if train else 0.0),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        p = self.img_dir / f\"{r['id_code']}.png\"\n",
        "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfm(image=img)['image']\n",
        "        y = torch.tensor(float(r['diagnosis']), dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "def sanity_train_b0_fold0(epochs=5, bs=8, lr=1e-4):\n",
        "    # Clamp batch size to avoid CUDA OOM in FP32 B0@512\n",
        "    if bs > 2:\n",
        "        print(f\"[Info] Reducing batch size from {bs} to 2 to prevent OOM.\")\n",
        "        bs = 2\n",
        "    folds = pd.read_csv('folds_s42_k5.csv')\n",
        "    trn_df = folds[folds.fold != 0].copy()\n",
        "    val_df = folds[folds.fold == 0].copy()\n",
        "    trn_ds = CacheDS(trn_df, CACHE_DIR, train=True)\n",
        "    val_ds = CacheDS(val_df, CACHE_DIR, train=False)\n",
        "    trn_loader = DataLoader(trn_ds, batch_size=bs, shuffle=True, num_workers=2, pin_memory=(DEVICE=='cuda'))\n",
        "    val_loader = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=2, pin_memory=(DEVICE=='cuda'))\n",
        "\n",
        "    model = timm.create_model('tf_efficientnet_b0_ns', pretrained=True, num_classes=1).to(DEVICE)\n",
        "    # Explicitly disable grad checkpointing to avoid CheckpointError\n",
        "    try:\n",
        "        model.set_grad_checkpointing(False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    if DEVICE=='cuda':\n",
        "        model = model.to(memory_format=torch.channels_last)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    crit = nn.SmoothL1Loss(reduction='mean')\n",
        "\n",
        "    best_q = -1.0; best_pred = None\n",
        "    y_val = val_df['diagnosis'].values.astype(int)\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        for xb, yb in trn_loader:\n",
        "            xb = xb.to(DEVICE, non_blocking=True)\n",
        "            if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "            yb = yb.to(DEVICE, non_blocking=True)\n",
        "            out = model(xb).squeeze(1)\n",
        "            loss = crit(out, yb)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        # Validate\n",
        "        model.eval(); preds = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in val_loader:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "                p = model(xb).squeeze(1).float()\n",
        "                preds.append(p.detach().cpu().numpy())\n",
        "        preds = np.concatenate(preds)\n",
        "        cuts = optimize_thresholds(preds, y_val)\n",
        "        q = qwk(y_val, apply_thresholds(preds, cuts))\n",
        "        print(f'Epoch {ep}: val_qwk_opt={q:.4f}, preds(mean/std)=({preds.mean():.3f}/{preds.std():.3f})')\n",
        "        if q > best_q: best_q, best_pred = q, preds.copy()\n",
        "        if DEVICE=='cuda': torch.cuda.empty_cache()\n",
        "    return best_q\n",
        "\n",
        "print('Minimal B0@512 regression sanity runner ready (FP32). Run sanity_train_b0_fold0() to verify learning.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f9210207-aaf3-42c0-97f1-8734a9ef9d34",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Execute minimal B0@512 sanity run (single fold, few epochs) to validate pipeline\n",
        "best_q = sanity_train_b0_fold0(epochs=6, bs=8, lr=1e-4)\n",
        "print('Sanity Fold0 best QWK (opt thresholds):', best_q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "20624b2d-f5cc-462c-a163-4f7a68963a80",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Enhanced B0@512 single-fold trainer with sampler, aug, AMP, accumulation, clipping, cosine LR\n",
        "import math, numpy as np, pandas as pd, torch, timm, albumentations as A, cv2, random\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from pathlib import Path\n",
        "\n",
        "cfg = {\n",
        "    'size': 512,\n",
        "    'epochs': 12,\n",
        "    'batch_size': 2,  # small to fit; use accumulation to simulate 8\n",
        "    'accum': 4,\n",
        "    'lr': 2e-4,\n",
        "    'weight_decay': 1e-5,\n",
        "    'model': 'tf_efficientnet_b0_ns',\n",
        "    'num_workers': 2,\n",
        "    'grad_clip': 1.0,\n",
        "    'seed': 42,\n",
        "}\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "CACHE_DIR = Path('cache_512/train')\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = (cfg['seed'] + worker_id) % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "seed_everything(cfg['seed'])\n",
        "\n",
        "def qwk(y_true, y_pred):\n",
        "    return cohen_kappa_score(np.asarray(y_true).astype(int), np.asarray(y_pred).astype(int), weights='quadratic')\n",
        "\n",
        "def apply_thresholds(preds, cuts):\n",
        "    t = np.sort(np.asarray(cuts).astype(float))\n",
        "    y = np.digitize(preds, t)\n",
        "    return np.clip(y, 0, 4).astype(int)\n",
        "\n",
        "def optimize_thresholds(preds, targets, init=[0.5,1.5,2.5,3.5]):\n",
        "    from scipy.optimize import minimize\n",
        "    preds = np.asarray(preds).ravel().astype(float)\n",
        "    targets = np.asarray(targets).ravel().astype(int)\n",
        "    def neg_qwk(c):\n",
        "        y = apply_thresholds(preds, c)\n",
        "        return -qwk(targets, y)\n",
        "    res = minimize(neg_qwk, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':500, 'xatol':1e-3, 'fatol':1e-3})\n",
        "    return np.sort(res.x)\n",
        "\n",
        "class CacheDSAug(Dataset):\n",
        "    def __init__(self, df, img_dir: Path, train=True, size=512):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.train = train\n",
        "        if train:\n",
        "            self.tfm = A.Compose([\n",
        "                A.Resize(size, size),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.Rotate(limit=10, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.4),\n",
        "                A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "        else:\n",
        "            self.tfm = A.Compose([\n",
        "                A.Resize(size, size),\n",
        "                A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        p = self.img_dir / f\"{r['id_code']}.png\"\n",
        "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfm(image=img)['image']\n",
        "        y = torch.tensor(float(r['diagnosis']), dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "def make_weighted_sampler(labels: np.ndarray):\n",
        "    vals, counts = np.unique(labels, return_counts=True)\n",
        "    freq = {v: c for v, c in zip(vals, counts)}\n",
        "    w_per_class = {v: 1.0 / c for v, c in freq.items()}\n",
        "    weights = np.array([w_per_class[int(y)] for y in labels], dtype=np.float32)\n",
        "    return WeightedRandomSampler(weights.tolist(), num_samples=len(weights), replacement=True)\n",
        "\n",
        "def train_enhanced_b0_fold0():\n",
        "    folds = pd.read_csv('folds_s42_k5.csv')\n",
        "    trn_df = folds[folds.fold != 0].copy()\n",
        "    val_df = folds[folds.fold == 0].copy()\n",
        "    trn_ds = CacheDSAug(trn_df, CACHE_DIR, train=True, size=cfg['size'])\n",
        "    val_ds = CacheDSAug(val_df, CACHE_DIR, train=False, size=cfg['size'])\n",
        "    sampler = make_weighted_sampler(trn_df['diagnosis'].values.astype(int))\n",
        "    gen_tr = torch.Generator(); gen_tr.manual_seed(cfg['seed'] + 123)\n",
        "    gen_va = torch.Generator(); gen_va.manual_seed(cfg['seed'] + 456)\n",
        "    trn_loader = DataLoader(trn_ds, batch_size=cfg['batch_size'], sampler=sampler, num_workers=cfg['num_workers'], pin_memory=(DEVICE=='cuda'), worker_init_fn=seed_worker, generator=gen_tr)\n",
        "    val_loader = DataLoader(val_ds, batch_size=max(2, cfg['batch_size']), shuffle=False, num_workers=cfg['num_workers'], pin_memory=(DEVICE=='cuda'), worker_init_fn=seed_worker, generator=gen_va)\n",
        "\n",
        "    model = timm.create_model(cfg['model'], pretrained=True, num_classes=1).to(DEVICE)\n",
        "    try: model.set_grad_checkpointing(False)\n",
        "    except Exception: pass\n",
        "    if DEVICE=='cuda': model = model.to(memory_format=torch.channels_last)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "    crit = nn.SmoothL1Loss(reduction='mean')\n",
        "\n",
        "    # Cosine schedule over total steps\n",
        "    steps_per_epoch = math.ceil(len(trn_loader) / max(1, cfg['accum']))\n",
        "    total_steps = cfg['epochs'] * steps_per_epoch\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=total_steps, eta_min=cfg['lr'] * 0.1)\n",
        "\n",
        "    best_q = -1.0\n",
        "    y_val = val_df['diagnosis'].values.astype(int)\n",
        "    global_step = 0\n",
        "    for ep in range(1, cfg['epochs'] + 1):\n",
        "        model.train()\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        for it, (xb, yb) in enumerate(trn_loader):\n",
        "            xb = xb.to(DEVICE, non_blocking=True)\n",
        "            if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "            yb = yb.to(DEVICE, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "                out = model(xb).squeeze(1)\n",
        "                loss = crit(out, yb) / cfg['accum']\n",
        "            scaler.scale(loss).backward() if DEVICE=='cuda' else loss.backward()\n",
        "            if ((it + 1) % cfg['accum'] == 0) or ((it + 1) == len(trn_loader)):\n",
        "                if DEVICE=='cuda': scaler.unscale_(opt)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['grad_clip'])\n",
        "                if DEVICE=='cuda':\n",
        "                    scaler.step(opt); scaler.update()\n",
        "                else:\n",
        "                    opt.step()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                scheduler.step()\n",
        "                global_step += 1\n",
        "\n",
        "        # Validate\n",
        "        model.eval(); preds = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in val_loader:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "                with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "                    p = model(xb).squeeze(1).float()\n",
        "                preds.append(p.detach().cpu().numpy())\n",
        "        preds = np.concatenate(preds)\n",
        "        cuts = optimize_thresholds(preds, y_val)\n",
        "        q = qwk(y_val, apply_thresholds(preds, cuts))\n",
        "        print(f'Epoch {ep}: val_qwk_opt={q:.4f}, lr={opt.param_groups[0][\"lr\"]:.2e}, pred_mean/std=({preds.mean():.3f}/{preds.std():.3f})')\n",
        "        if q > best_q: best_q = q\n",
        "        if DEVICE=='cuda': torch.cuda.empty_cache()\n",
        "    print('Enhanced sanity Fold0 best QWK:', best_q)\n",
        "    return best_q\n",
        "\n",
        "print('Enhanced B0@512 trainer ready: sampler+aug+AMP+accum+clip+cosine (deterministic). Run train_enhanced_b0_fold0() and aim for QWK>0.89.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "fc3a11ab-86d1-48e3-a563-cea0d5ce2af1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run enhanced single-fold training aiming for QWK > 0.89\n",
        "best_q_enh = train_enhanced_b0_fold0()\n",
        "print('Enhanced Fold0 best QWK:', best_q_enh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b9389002-6be6-420a-823f-d58c72f25cce",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5-fold CV for enhanced B0@512: EMA, early stopping, warmup+cosine, cleaner aug, accum=4, OOF+TTA submission\n",
        "import os, json, math, numpy as np, pandas as pd, torch, timm, cv2, random\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.optim.swa_utils import AveragedModel\n",
        "\n",
        "# Hard-disable any gradient checkpointing globally to avoid CheckpointError\n",
        "try:\n",
        "    import torch.utils.checkpoint as cp\n",
        "    cp.set_checkpoint_enabled(False)\n",
        "    print('[Init] torch.utils.checkpoint globally disabled')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "models_dir = Path('models'); models_dir.mkdir(exist_ok=True)\n",
        "oof_dir = Path('oof'); oof_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Ensure core config/globals exist\n",
        "if 'cfg' not in globals():\n",
        "    cfg = {\n",
        "        'size': 512,\n",
        "        'epochs': 20,\n",
        "        'batch_size': 2,\n",
        "        'accum': 4,\n",
        "        'lr': 2e-4,\n",
        "        'weight_decay': 1e-5,\n",
        "        'model': 'tf_efficientnet_b0_ns',\n",
        "        'num_workers': 2,\n",
        "        'grad_clip': 1.0,\n",
        "        'seed': 42,\n",
        "        'warmup_epochs': 1,\n",
        "        'patience': 5,\n",
        "        'ema_decay': 0.999,\n",
        "        'min_epochs': 8,\n",
        "    }\n",
        "else:\n",
        "    cfg['epochs'] = cfg.get('epochs', 20)\n",
        "    cfg['accum'] = 4\n",
        "    cfg['lr'] = 2e-4\n",
        "    cfg['warmup_epochs'] = cfg.get('warmup_epochs', 1)\n",
        "    cfg['patience'] = 5\n",
        "    cfg['ema_decay'] = cfg.get('ema_decay', 0.999)\n",
        "    cfg['seed'] = cfg.get('seed', 42)\n",
        "    cfg['size'] = 512\n",
        "    cfg['batch_size'] = 2\n",
        "    cfg['weight_decay'] = cfg.get('weight_decay', 1e-5)\n",
        "    cfg['model'] = cfg.get('model', 'tf_efficientnet_b0_ns')\n",
        "    cfg['num_workers'] = 2\n",
        "    cfg['grad_clip'] = cfg.get('grad_clip', 1.0)\n",
        "    cfg['min_epochs'] = cfg.get('min_epochs', 8)\n",
        "if 'DEVICE' not in globals():\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if 'IMAGENET_MEAN' not in globals(): IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "if 'IMAGENET_STD' not in globals(): IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Ensure deterministic seeding utilities exist in this scope\n",
        "if 'seed_everything' not in globals():\n",
        "    def seed_everything(seed: int):\n",
        "        random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "        if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
        "if 'seed_worker' not in globals():\n",
        "    def seed_worker(worker_id):\n",
        "        base = globals().get('cfg', {}).get('seed', 42)\n",
        "        worker_seed = (int(base) + int(worker_id)) % (2**32)\n",
        "        np.random.seed(worker_seed); random.seed(worker_seed)\n",
        "\n",
        "# Expect apply_thresholds, optimize_thresholds, qwk defined earlier; if not, define minimal fallbacks\n",
        "if 'apply_thresholds' not in globals():\n",
        "    def apply_thresholds(preds, cuts):\n",
        "        t = np.sort(np.asarray(cuts).astype(float)); y = np.digitize(preds, t)\n",
        "        return np.clip(y, 0, 4).astype(int)\n",
        "if 'optimize_thresholds' not in globals():\n",
        "    def optimize_thresholds(preds, targets, init=[0.5,1.5,2.5,3.5]):\n",
        "        from scipy.optimize import minimize\n",
        "        from sklearn.metrics import cohen_kappa_score\n",
        "        def qwk_local(y_true, y_pred):\n",
        "            return cohen_kappa_score(np.asarray(y_true).astype(int), np.asarray(y_pred).astype(int), weights='quadratic')\n",
        "        preds = np.asarray(preds).ravel().astype(float); targets = np.asarray(targets).ravel().astype(int)\n",
        "        def neg_qwk(c): return -qwk_local(targets, apply_thresholds(preds, c))\n",
        "        res = minimize(neg_qwk, x0=np.array(init, dtype=float), method='Nelder-Mead', options={'maxiter':500,'xatol':1e-3,'fatol':1e-3})\n",
        "        return np.sort(res.x)\n",
        "if 'qwk' not in globals():\n",
        "    from sklearn.metrics import cohen_kappa_score\n",
        "    def qwk(y_true, y_pred):\n",
        "        return cohen_kappa_score(np.asarray(y_true).astype(int), np.asarray(y_pred).astype(int), weights='quadratic')\n",
        "\n",
        "class CacheTestDS(Dataset):\n",
        "    def __init__(self, df, img_dir: Path, size: int):\n",
        "        self.df = df.reset_index(drop=True); self.img_dir = Path(img_dir)\n",
        "        self.tfm = A.Compose([A.Resize(size, size), A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD), ToTensorV2()])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]; p = self.img_dir / f\"{row['id_code']}.png\"\n",
        "        img = cv2.imread(str(p), cv2.IMREAD_COLOR); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfm(image=img)['image']; return x, -1.0\n",
        "\n",
        "def make_weighted_sampler(labels: np.ndarray):\n",
        "    vals, counts = np.unique(labels, return_counts=True); wpc = {int(v): 1.0/float(c) for v, c in zip(vals, counts)}\n",
        "    weights = np.array([wpc[int(y)] for y in labels], dtype=np.float32)\n",
        "    return WeightedRandomSampler(weights.tolist(), num_samples=len(weights), replacement=True)\n",
        "\n",
        "class CacheDSAugCV(Dataset):\n",
        "    def __init__(self, df, img_dir: Path, train=True, size=512):\n",
        "        self.df = df.reset_index(drop=True); self.img_dir = Path(img_dir)\n",
        "        if train:\n",
        "            self.tfm = A.Compose([\n",
        "                A.Resize(size, size),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.Rotate(limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "        else:\n",
        "            self.tfm = A.Compose([A.Resize(size, size), A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD), ToTensorV2()])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]; p = self.img_dir / f\"{r['id_code']}.png\"\n",
        "        img = cv2.imread(str(p), cv2.IMREAD_COLOR); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        x = self.tfm(image=img)['image']; y = torch.tensor(float(r['diagnosis']), dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "def _warmup_cosine_lr(step, total_steps, base_lr, warmup_steps):\n",
        "    if step < warmup_steps:\n",
        "        return base_lr * (step + 1) / max(1, warmup_steps)\n",
        "    t = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
        "    return base_lr * 0.5 * (1.0 + math.cos(math.pi * t))\n",
        "\n",
        "def train_one_fold_b0_enh(fold: int):\n",
        "    # Also ensure checkpointing disabled inside function scope\n",
        "    try:\n",
        "        import torch.utils.checkpoint as cp\n",
        "        cp.set_checkpoint_enabled(False)\n",
        "    except Exception:\n",
        "        pass\n",
        "    base_seed = cfg.get('seed', 42); seed_everything(int(base_seed) + int(fold))\n",
        "    folds = pd.read_csv('folds_s42_k5.csv')\n",
        "    trn_df = folds[folds.fold != fold].copy(); val_df = folds[folds.fold == fold].copy()\n",
        "    trn_ds = CacheDSAugCV(trn_df, Path('cache_512/train'), train=True, size=cfg['size']); val_ds = CacheDSAugCV(val_df, Path('cache_512/train'), train=False, size=cfg['size'])\n",
        "    sampler = make_weighted_sampler(trn_df['diagnosis'].values.astype(int))\n",
        "    gen_tr = torch.Generator(); gen_tr.manual_seed(int(base_seed) + 1000 + int(fold))\n",
        "    gen_va = torch.Generator(); gen_va.manual_seed(int(base_seed) + 2000 + int(fold))\n",
        "    trn_loader = DataLoader(trn_ds, batch_size=cfg['batch_size'], sampler=sampler, num_workers=cfg['num_workers'], pin_memory=(DEVICE=='cuda'), worker_init_fn=seed_worker, generator=gen_tr)\n",
        "    val_loader = DataLoader(val_ds, batch_size=max(2, cfg['batch_size']), shuffle=False, num_workers=cfg['num_workers'], pin_memory=(DEVICE=='cuda'), worker_init_fn=seed_worker, generator=gen_va)\n",
        "\n",
        "    model = timm.create_model(cfg['model'], pretrained=True, num_classes=1).to(DEVICE)\n",
        "    # Robustly disable any gradient checkpointing\n",
        "    try: model.set_grad_checkpointing(False)\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        from timm.layers import set_grad_checkpointing as timm_set_gc\n",
        "        timm_set_gc(model, False)\n",
        "    except Exception:\n",
        "        try:\n",
        "            from timm.models.layers import set_grad_checkpointing as timm_set_gc_legacy\n",
        "            timm_set_gc_legacy(model, False)\n",
        "        except Exception:\n",
        "            pass\n",
        "    if hasattr(model, 'grad_checkpointing'):\n",
        "        try: model.grad_checkpointing = False\n",
        "        except Exception: pass\n",
        "    if DEVICE=='cuda': model = model.to(memory_format=torch.channels_last)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
        "    # Disable AMP to avoid any interaction with checkpointing\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=False)\n",
        "    crit = torch.nn.SmoothL1Loss(reduction='mean')\n",
        "    ema_model = AveragedModel(model, avg_fn=None)\n",
        "\n",
        "    steps_per_epoch = math.ceil(len(trn_loader) / max(1, cfg['accum']))\n",
        "    total_steps = max(1, cfg['epochs'] * steps_per_epoch)\n",
        "    warmup_steps = int(cfg['warmup_epochs'] * steps_per_epoch)\n",
        "\n",
        "    best_q = -1.0; best_preds = None\n",
        "    y_val = val_df['diagnosis'].values.astype(int)\n",
        "    global_step = 0; epochs_no_improve = 0\n",
        "    for ep in range(1, cfg['epochs'] + 1):\n",
        "        model.train(); opt.zero_grad(set_to_none=True)\n",
        "        running_loss = 0.0; n_loss = 0\n",
        "        for it, (xb, yb) in enumerate(trn_loader):\n",
        "            xb = xb.to(DEVICE, non_blocking=True);\n",
        "            if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "            yb = yb.to(DEVICE, non_blocking=True)\n",
        "            # FP32 forward (no autocast) to avoid checkpoint incompatibilities\n",
        "            out = model(xb).squeeze(1); loss = crit(out, yb) / cfg['accum']\n",
        "            loss.backward()\n",
        "            running_loss += loss.detach().float().item(); n_loss += 1\n",
        "            if ((it + 1) % cfg['accum'] == 0) or ((it + 1) == len(trn_loader)):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['grad_clip'])\n",
        "                opt.step()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                # Correct EMA update\n",
        "                ema_model.update_parameters(model)\n",
        "                # Per-step LR schedule (warmup + cosine)\n",
        "                global_step += 1\n",
        "                lr_now = _warmup_cosine_lr(global_step, total_steps, cfg['lr'], warmup_steps)\n",
        "                for pg in opt.param_groups: pg['lr'] = lr_now\n",
        "\n",
        "        # Update BN stats of EMA before validation\n",
        "        try:\n",
        "            torch.optim.swa_utils.update_bn(trn_loader, ema_model, device=DEVICE)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # Validate EMA\n",
        "        ema_model.eval(); preds_ema = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in val_loader:\n",
        "                xb = xb.to(DEVICE, non_blocking=True);\n",
        "                if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "                p = ema_model(xb).squeeze(1).float()\n",
        "                preds_ema.append(p.detach().cpu().numpy())\n",
        "        preds_ema = np.concatenate(preds_ema)\n",
        "        cuts_ema = optimize_thresholds(preds_ema, y_val); q_ema = qwk(y_val, apply_thresholds(preds_ema, cuts_ema))\n",
        "\n",
        "        # Validate base model too\n",
        "        model.eval(); preds_base = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in val_loader:\n",
        "                xb = xb.to(DEVICE, non_blocking=True);\n",
        "                if DEVICE=='cuda': xb = xb.contiguous(memory_format=torch.channels_last)\n",
        "                p = model(xb).squeeze(1).float()\n",
        "                preds_base.append(p.detach().cpu().numpy())\n",
        "        preds_base = np.concatenate(preds_base)\n",
        "        cuts_base = optimize_thresholds(preds_base, y_val); q_base = qwk(y_val, apply_thresholds(preds_base, cuts_base))\n",
        "\n",
        "        avg_loss = (running_loss / max(1, n_loss)) * cfg['accum']\n",
        "        print(f\"[Fold {fold}] Epoch {ep}: loss={avg_loss:.4f}, lr={opt.param_groups[0]['lr']:.2e}, Q_base={q_base:.4f} (m/s={preds_base.mean():.3f}/{preds_base.std():.3f}), Q_ema={q_ema:.4f} (m/s={preds_ema.mean():.3f}/{preds_ema.std():.3f})\")\n",
        "\n",
        "        q_curr = max(q_ema, q_base); use_ema = (q_ema >= q_base); cuts_curr = (cuts_ema if use_ema else cuts_base); preds_curr = (preds_ema if use_ema else preds_base)\n",
        "        if q_curr > best_q + 1e-4:\n",
        "            best_q = q_curr; best_preds = preds_curr.copy()\n",
        "            torch.save({'model': ema_model.state_dict()}, models_dir / f'b0_512_enh_v2_ema_fold{int(fold)}.pt')\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "        if (ep >= int(cfg['min_epochs'])) and (epochs_no_improve >= int(cfg['patience'])):\n",
        "            print(f'[Fold {fold}] Early stopping at epoch {ep} (best QWK={best_q:.4f})')\n",
        "            break\n",
        "        if DEVICE=='cuda': torch.cuda.empty_cache()\n",
        "    return best_preds, y_val, float(best_q)\n",
        "\n",
        "def run_cv_b0_enh_and_submit():\n",
        "    folds = pd.read_csv('folds_s42_k5.csv')\n",
        "    oof_preds = np.zeros(len(folds), dtype=np.float32); oof_tgts = folds['diagnosis'].values.astype(int); fold_q = []\n",
        "    for fold in sorted(folds['fold'].unique()):\n",
        "        preds, y_val, bq = train_one_fold_b0_enh(int(fold))\n",
        "        idx = folds.index[folds.fold == fold].to_numpy(); oof_preds[idx] = preds; fold_q.append(bq)\n",
        "        print(f'Fold {fold} best QWK: {bq:.4f}')\n",
        "    np.save(oof_dir / 'b0_512_enh_v2_oof_preds.npy', oof_preds)\n",
        "    np.save(oof_dir / 'b0_512_enh_v2_oof_targets.npy', oof_tgts)\n",
        "    cuts = optimize_thresholds(oof_preds, oof_tgts).tolist()\n",
        "    with open('thresholds_b0_512_enh_v2.json', 'w') as fh: json.dump({'cuts': cuts}, fh)\n",
        "    print('OOF QWK (opt):', qwk(oof_tgts, apply_thresholds(oof_preds, cuts)), 'per-fold:', fold_q)\n",
        "\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "    test_ds = CacheTestDS(test_df, Path('cache_512/test'), size=cfg['size'])\n",
        "    test_loader = DataLoader(test_ds, batch_size=2, shuffle=False, num_workers=cfg['num_workers'], pin_memory=(DEVICE=='cuda'), worker_init_fn=seed_worker)\n",
        "    all_fold_preds = []\n",
        "    for fold in sorted(folds['fold'].unique()):\n",
        "        model = timm.create_model(cfg['model'], pretrained=False, num_classes=1).to(DEVICE)\n",
        "        try: model.set_grad_checkpointing(False)\n",
        "        except Exception: pass\n",
        "        try:\n",
        "            from timm.layers import set_grad_checkpointing as timm_set_gc\n",
        "            timm_set_gc(model, False)\n",
        "        except Exception:\n",
        "            try:\n",
        "                from timm.models.layers import set_grad_checkpointing as timm_set_gc_legacy\n",
        "                timm_set_gc_legacy(model, False)\n",
        "            except Exception:\n",
        "                pass\n",
        "        if DEVICE=='cuda': model = model.to(memory_format=torch.channels_last)\n",
        "        ck = torch.load(models_dir / f'b0_512_enh_v2_ema_fold{int(fold)}.pt', map_location='cpu', weights_only=True)\n",
        "        model.load_state_dict(ck['model'], strict=True); model.eval()\n",
        "        preds_fold = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in test_loader:\n",
        "                xb = xb.to(DEVICE, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
        "                xb_flip = torch.flip(xb, dims=[3])\n",
        "                # FP32 inference (no autocast) for safety\n",
        "                p1 = model(xb).squeeze(1).float(); p2 = model(xb_flip).squeeze(1).float(); p = 0.5 * (p1 + p2)\n",
        "                preds_fold.append(p.detach().cpu().numpy())\n",
        "        all_fold_preds.append(np.concatenate(preds_fold)); del model; torch.cuda.empty_cache()\n",
        "    test_preds = np.mean(np.stack(all_fold_preds, axis=0), axis=0); labels = apply_thresholds(test_preds, cuts)\n",
        "    sub = pd.DataFrame({'id_code': test_df['id_code'], 'diagnosis': labels}); sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv with EMA 5-fold TTA. Shape:', sub.shape)\n",
        "\n",
        "print('5-fold CV (EMA+update_bn+dual-val+relaxed-ES+warmup+cosine+clean aug+accum=4, size=512, bs=2, nw=2, lr=2e-4, no-checkpointing) ready: run run_cv_b0_enh_and_submit().')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-fold CV (EMA+update_bn+dual-val+relaxed-ES+warmup+cosine+clean aug+accum=4, size=512, bs=2, nw=2, lr=2e-4, no-checkpointing) ready: run run_cv_b0_enh_and_submit().\n"
          ]
        }
      ]
    },
    {
      "id": "3f4118ab-67ad-40c9-8343-4997155db10c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run full 5-fold CV with enhanced B0@512 and generate submission.csv\n",
        "import time\n",
        "t0 = time.time()\n",
        "run_cv_b0_enh_and_submit()\n",
        "print(f'Total wall-clock: {(time.time()-t0)/60:.1f} min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a214a2b1-968e-4cf6-ab8f-f5830cbf18bc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Single-fold sanity check for v2 pipeline (expect QWK >= 0.89 before full CV)\n",
        "import time\n",
        "t0 = time.time()\n",
        "preds_fold0, y_val_fold0, best_q_fold0 = train_one_fold_b0_enh(0)\n",
        "print(f\"Fold 0 sanity check \u2014 best QWK: {best_q_fold0:.4f}. Wall-clock: {(time.time()-t0)/60:.1f} min\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}